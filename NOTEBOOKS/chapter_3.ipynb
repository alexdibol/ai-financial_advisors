{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPCa1GwEuYrIxXwAQLmQG2k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**AI FINANCIAL ADVISOR CHAPTER 3: AGENTS**\n","\n","---"],"metadata":{"id":"cnQK8yTVMAhC"}},{"cell_type":"markdown","source":["##0.REFERENCE"],"metadata":{"id":"tw2-7uYoMGHg"}},{"cell_type":"markdown","source":["https://claude.ai/share/3ae229b5-6333-41a7-a66d-c85618e02ae3"],"metadata":{"id":"axSMA0YpNnYX"}},{"cell_type":"markdown","source":["##1.CONTEXT"],"metadata":{"id":"4LFo5LtiMIff"}},{"cell_type":"markdown","source":["**Understanding Structured AI Reasoning for Financial Advisors: A New Paradigm Beyond Simple Chatbots**\n","\n","When most people think about interacting with artificial intelligence, they imagine typing questions into a chat window and receiving conversational answers. This traditional chatbot interaction works well for general inquiries, creative writing, or casual research. You ask a question, the AI responds with text, and the conversation flows naturally without any particular structure or documentation. However, this informal approach presents serious challenges in regulated industries like financial services, where every recommendation must be documented, every assumption must be traceable, and every decision must withstand regulatory scrutiny.\n","\n","This notebook represents a fundamentally different approach to working with AI in professional advisory contexts. Instead of casual conversation, it implements what we call structured reasoning with comprehensive governance controls. The difference is profound and addresses the core challenge facing financial advisors who want to leverage AI capabilities while remaining compliant with regulations like Regulation Best Interest, fiduciary standards, and recordkeeping requirements.\n","\n","In a traditional chatbot interaction, you might ask something like \"What should my client do with their concentrated stock position?\" and receive a narrative response discussing various options. The problem is that this response disappears unless you manually copy it somewhere. There's no automatic record of what assumptions the AI made, no documentation of what alternatives were considered, no log of the exact question asked, and no systematic way to verify that the AI didn't cross boundaries by making recommendations that only a qualified human advisor should make. If a regulator later questions your advice, you have no defensible trail showing how you used AI in your process.\n","\n","This notebook solves these problems through four fundamental innovations that transform AI from an uncontrolled conversational tool into a governed reasoning assistant.\n","\n","**First, the notebook enforces strict boundaries through what we call Level Two reasoning.** Traditional chatbots will happily tell you what to recommend, which securities to buy, or whether something is suitable for a client. This notebook's architecture prevents the AI from crossing those lines. It's programmed to separate facts from assumptions, identify alternatives without recommending any particular one, surface questions that need human judgment, and detect gaps in information. The AI acts as a reasoning scaffold that organizes thinking rather than a decision-maker that replaces professional judgment. Every prompt sent to the AI explicitly reinforces these boundaries, and automated risk detection scans responses for language that would indicate the AI overstepped its role.\n","\n","**Second, the notebook creates comprehensive audit trails that make every interaction traceable and defensible.** When you use a traditional chatbot, the conversation happens and then it's gone unless you manually save it. This notebook automatically logs every prompt sent to the AI and every response received, with both redacted to protect confidentiality. Each log entry includes cryptographic hashes that create an immutable chain, meaning any tampering would be immediately detectable. The system also generates a run manifest that documents exactly which AI model was used, what parameters controlled its behavior, and what governance rules were in effect. If you need to demonstrate to a compliance officer or regulator that you used AI appropriately, you can provide the complete bundle showing exactly what happened, when it happened, and under what controls.\n","\n","**Third, the notebook implements systematic risk detection that identifies potential problems in real time.** As the AI generates responses, automated scanners check for recommendation language like \"you should\" or \"I recommend,\" invented authority like fabricated SEC rules or FINRA requirements, missing disclaimers that should appear in every output, insufficient alternatives when multiple options should be presented, and gaps in critical information that would make any analysis incomplete. Each detected risk gets logged with severity ratings, creating a risk register that supervisors can review. This is fundamentally different from hoping you'll notice problems yourself in a casual chat conversation.\n","\n","**Fourth, the notebook produces structured deliverables rather than free-form text.** Instead of getting paragraphs of narrative that you need to interpret and extract value from, the AI returns information in standardized JSON format with specific fields for facts, assumptions, alternatives, open questions, analysis, and risks. This structure ensures consistency across cases, makes information easy to find and review, enables automated quality checks, and creates artifacts that can be directly incorporated into supervision files. The structured format also means you can build workflows where one advisor's reasoning artifacts become inputs for supervisor review or peer consultation.\n","\n","The practical benefits for financial advisory practices are substantial. Imagine an advisor preparing for a client meeting about retirement income planning. In the traditional chatbot approach, the advisor might have several informal conversations with AI, getting various suggestions and ideas, but ending up with nothing documented and no clear separation between the AI's input and the advisor's own professional judgment. With this structured reasoning system, the advisor inputs sanitized client facts, receives back a reasoning map that clearly separates what's known from what's assumed from what's unknown, gets a comparison of alternative approaches without any recommendations, sees questions surfaced about information gaps, and obtains all of this in documented JSON files with full audit trails showing the AI stayed within appropriate boundaries.\n","\n","For compliance officers and supervisors, the benefits are equally compelling. Traditional chatbot usage is nearly impossible to supervise effectively because there's no systematic way to know what advisors asked, what responses they received, or how they used those responses. This notebook produces a complete bundle for every run including the governance manifest showing what rules were in effect, immutable logs of all AI interactions, risk registers flagging potential issues, and structured outputs for each case that can be reviewed against standardized criteria. The supervisor can verify that facts were separated from assumptions, that multiple alternatives were identified, that no recommendations were made, and that all regulatory references were marked as unverified.\n","\n","The importance of this approach extends beyond individual compliance. In regulated industries, the question is not whether professionals will use AI tools, but whether they'll use them in ways that create liability or in ways that enhance quality while maintaining defensibility. Traditional chatbot usage creates hidden risks because it happens in the shadows without documentation, encourages boundary violations because the AI naturally wants to be helpful by making recommendations, provides no systematic quality control, and leaves no trail for supervision or regulatory examination.\n","\n","Structured reasoning with governance controls brings AI usage into the light. It creates transparency through comprehensive logging, enforces appropriate boundaries through architecture rather than hoping users will self-regulate, enables supervision through standardized outputs and risk registers, and produces defensible artifacts that demonstrate responsible use. This transforms AI from a compliance risk into a compliance-positive tool that actually strengthens your documentation and supervision processes.\n","\n","The notebook's approach recognizes a fundamental truth about AI in professional services: the technology is powerful but must be channeled appropriately. Just as financial advisors use sophisticated analytical tools but remain responsible for recommendations, this system lets advisors leverage AI's reasoning capabilities while maintaining clear human accountability. The AI structures information, identifies considerations, and surfaces questions, but the qualified human advisor still makes all judgments about suitability, best interest, and appropriate courses of action.\n","\n","For practices considering AI adoption, this notebook demonstrates that the choice is not between using AI or avoiding it, but between using AI recklessly or using it responsibly. The structured governance approach shown here provides a template for bringing powerful AI capabilities into regulated advisory work without creating the documentation gaps, boundary violations, or supervision challenges that would come from treating AI as just another chatbot to have casual conversations with. This is how professional services can harness transformative technology while honoring the regulatory frameworks that protect investors and maintain market integrity."],"metadata":{"id":"6n-x0MLbMKUs"}},{"cell_type":"markdown","source":["##2.LIBRARIES AND ENVIRONMENT"],"metadata":{"id":"HzSSYRQ0MKs8"}},{"cell_type":"code","source":["# Cell 2\n","# Goal: Install dependencies, imports, and create run directory structure\n","# Output: Confirmation messages showing setup completion\n","\n","!pip install -q anthropic\n","\n","import anthropic\n","import os\n","import json\n","import hashlib\n","import uuid\n","from datetime import datetime\n","from typing import Dict, List, Any, Optional\n","from pathlib import Path\n","import zipfile\n","\n","# Create run directory structure\n","RUN_ID = f\"run_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}\"\n","RUN_DIR = Path(f\"/content/{RUN_ID}\")\n","DELIVERABLES_DIR = RUN_DIR / \"deliverables\"\n","LOGS_DIR = RUN_DIR / \"logs\"\n","\n","RUN_DIR.mkdir(exist_ok=True)\n","DELIVERABLES_DIR.mkdir(exist_ok=True)\n","LOGS_DIR.mkdir(exist_ok=True)\n","\n","print(f\"‚úì Dependencies installed\")\n","print(f\"‚úì Run directory created: {RUN_DIR}\")\n","print(f\"‚úì Run ID: {RUN_ID}\")\n","print(f\"‚úì Deliverables: {DELIVERABLES_DIR}\")\n","print(f\"‚úì Logs: {LOGS_DIR}\")"],"metadata":{"id":"TOYUwL9vMKKC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768492535817,"user_tz":360,"elapsed":6157,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"84e8d7dd-8f85-4b8e-d408-e4fc902d5a21"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/390.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m389.1/390.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m390.3/390.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h‚úì Dependencies installed\n","‚úì Run directory created: /content/run_20260115_155535_110b2989\n","‚úì Run ID: run_20260115_155535_110b2989\n","‚úì Deliverables: /content/run_20260115_155535_110b2989/deliverables\n","‚úì Logs: /content/run_20260115_155535_110b2989/logs\n"]}]},{"cell_type":"markdown","source":["##3.CLAUDE API AND CLIENT INITIALIZATION"],"metadata":{"id":"STtjBQgwMNHi"}},{"cell_type":"markdown","source":["###3.1.OVERVIEW"],"metadata":{"id":"ShWjt_vyMO17"}},{"cell_type":"markdown","source":["\n","\n","When you run Cell 3, the notebook attempts to connect to the Anthropic AI service using your API key. Think of this like logging into a service - you need credentials to access it.\n","\n","The cell first looks for your API key in Colab's secure storage area called Secrets. This is similar to how password managers store your passwords safely. If the key is found, the notebook creates a connection object called \"client\" that will be used throughout the notebook to communicate with the Claude AI model.\n","\n","You'll see a success message confirming the API client is ready, along with details about which AI model will be used. The model specified is claude-sonnet-4-5-20250929, which is a specific version of Claude designed for complex reasoning tasks. The configuration also shows that responses will be limited to 4096 tokens (roughly 3000-3500 words) and the temperature is set to 0.2, meaning responses will be focused and consistent rather than creative or varied.\n","\n","If the API key is not found, you'll see an error message with step-by-step instructions. The instructions guide you to add your Anthropic API key to Colab's Secrets manager. This involves clicking the key icon in the left sidebar, creating a new secret named ANTHROPIC_API_KEY, pasting your actual API key as the value, and enabling notebook access. This security approach ensures your API key is never visible in the notebook code itself, protecting it from accidental exposure.\n","\n","The error handling is designed to be educational - it doesn't just fail silently but instead teaches you exactly what needs to be configured. This is important because without a valid API key, none of the AI agents in the notebook can function. The connection established here becomes the foundation for all subsequent AI-powered operations in the workflow.\n","\n","Once successful, this cell essentially opens the communication channel between your notebook and Anthropic's AI service, allowing the financial advisory workflow agents to process scenarios, generate drafts, and create governance artifacts throughout the remaining cells."],"metadata":{"id":"U0hNWRDxgb7J"}},{"cell_type":"markdown","source":["###3.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"Xml9f9GoMR7J"}},{"cell_type":"code","source":["# Cell 3\n","# Goal: Initialize Anthropic API client with key from Colab secrets\n","# Output: Confirmation of successful API client initialization\n","\n","from google.colab import userdata\n","\n","try:\n","    ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n","    os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n","    client = anthropic.Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n","    print(\"‚úì Anthropic API client initialized successfully\")\n","    print(\"‚úì Model: claude-sonnet-4-5-20250929\")\n","    print(\"‚úì Max tokens: 4096 (increased for complete JSON responses)\")\n","    print(\"‚úì Temperature: 0.2\")\n","except Exception as e:\n","    print(f\"‚ùå Error: {e}\")\n","    print(\"\\n‚ö†Ô∏è Setup required:\")\n","    print(\"1. Click the üîë key icon in the left sidebar (Secrets)\")\n","    print(\"2. Add a new secret named: ANTHROPIC_API_KEY\")\n","    print(\"3. Paste your Anthropic API key as the value\")\n","    print(\"4. Enable 'Notebook access' toggle\")\n","    print(\"5. Re-run this cell\")\n","    raise"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ikSZdNHVaYOD","executionInfo":{"status":"ok","timestamp":1768493367829,"user_tz":360,"elapsed":457,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"c75877eb-094e-4ad0-c2a3-e4188370b8f0"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Anthropic API client initialized successfully\n","‚úì Model: claude-sonnet-4-5-20250929\n","‚úì Max tokens: 4096 (increased for complete JSON responses)\n","‚úì Temperature: 0.2\n"]}]},{"cell_type":"markdown","source":["##4.MANIFEST AND LOGGING INFRASTRUCTURE"],"metadata":{"id":"zSjFjeDuMaZn"}},{"cell_type":"markdown","source":["###4.1.OVERVIEW"],"metadata":{"id":"6OWXlpZoMcHa"}},{"cell_type":"markdown","source":["\n","\n","Cell 4 creates the foundational record-keeping infrastructure for the entire workflow. Think of this as setting up a new filing cabinet system before starting any work - everything that happens later will be organized according to the structure created here.\n","\n","The cell first generates a unique identifier for this notebook run, combining the current date, time, and a random code. This run identifier acts like a case number in a law firm - it allows you to distinguish this particular execution from any other time you run the notebook. Every file, log entry, and artifact created during this session will be tagged with this identifier.\n","\n","Next, the cell creates a manifest file, which is essentially a detailed label describing this entire package. The manifest records what AI model was used, what settings were applied, when the run started, and who authored the notebook. It also includes a configuration hash, which is like a fingerprint of all the settings used. This hash allows anyone reviewing the work later to verify that the configuration hasn't been changed since the run completed.\n","\n","The cell then initializes two critical logging systems. The first is the prompts log, which will record every interaction with the AI in an immutable chain. Immutable means once something is written, it cannot be changed or deleted - similar to how blockchain records work. This log starts with a genesis entry, like the first block in a blockchain, which begins the hash chain. Each subsequent log entry will mathematically link to the previous one, creating a tamper-evident audit trail.\n","\n","The second log is the risk register, starting as an empty list ready to capture any issues detected during workflow execution. This might include risks like missing information, potential conflicts of interest, or workflow integrity problems.\n","\n","When this cell completes successfully, you'll see confirmation messages showing where each file was created, along with the configuration hash. This setup ensures complete traceability - a supervisor or auditor can later verify exactly what happened, when it happened, and under what configuration, which is essential for regulatory compliance in financial advisory contexts."],"metadata":{"id":"XdRc9-nEMeIF"}},{"cell_type":"markdown","source":["###4.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"GvnsRIc6Mefx"}},{"cell_type":"code","source":["# Cell 4\n","# Goal: Create manifest and initialize immutable logging infrastructure\n","# Output: Manifest file created with run metadata and hash chain initialized\n","\n","# Generate manifest\n","ENV_FINGERPRINT = {\n","    \"python_version\": \"3.10+\",\n","    \"colab\": True,\n","    \"model\": \"claude-sonnet-4-5-20250929\",\n","    \"temperature\": 0.2,\n","    \"max_tokens\": 1200\n","}\n","\n","CONFIG_HASH = hashlib.sha256(\n","    json.dumps(ENV_FINGERPRINT, sort_keys=True).encode()\n",").hexdigest()[:16]\n","\n","MANIFEST = {\n","    \"run_id\": RUN_ID,\n","    \"timestamp\": datetime.now().isoformat(),\n","    \"author\": \"Alejandro Reynoso, Chief Scientist DEFI CAPITAL RESEARCH\",\n","    \"chapter\": \"Chapter 3 - Level 3 (Agents)\",\n","    \"model\": \"claude-sonnet-4-5-20250929\",\n","    \"temperature\": 0.2,\n","    \"max_tokens\": 1200,\n","    \"config_hash\": CONFIG_HASH,\n","    \"env_fingerprint\": ENV_FINGERPRINT,\n","    \"scope\": \"Agentic advisory workflows with human-in-the-loop checkpoints\",\n","    \"disclaimer\": \"NOT INVESTMENT, TAX, OR LEGAL ADVICE. Draft assistance only. Qualified advisor review required.\"\n","}\n","\n","manifest_path = RUN_DIR / \"run_manifest.json\"\n","with open(manifest_path, \"w\") as f:\n","    json.dump(MANIFEST, f, indent=2)\n","\n","# Initialize immutable log with genesis entry\n","prompts_log_path = LOGS_DIR / \"prompts_log.jsonl\"\n","genesis_entry = {\n","    \"step_id\": \"genesis\",\n","    \"timestamp\": datetime.now().isoformat(),\n","    \"agent_name\": \"Logger\",\n","    \"prompt_hash\": \"0\" * 64,\n","    \"response_hash\": \"0\" * 64,\n","    \"prev_hash\": \"0\" * 64,\n","    \"redacted_prompt\": \"GENESIS BLOCK\",\n","    \"redacted_response\": \"Log initialized\"\n","}\n","with open(prompts_log_path, \"w\") as f:\n","    f.write(json.dumps(genesis_entry) + \"\\n\")\n","\n","# Initialize risk log\n","risk_log_path = LOGS_DIR / \"risk_log.json\"\n","with open(risk_log_path, \"w\") as f:\n","    json.dump({\"risks\": []}, f, indent=2)\n","\n","print(f\"‚úì Manifest created: {manifest_path}\")\n","print(f\"‚úì Immutable log initialized: {prompts_log_path}\")\n","print(f\"‚úì Risk log initialized: {risk_log_path}\")\n","print(f\"\\nConfig Hash: {CONFIG_HASH}\")"],"metadata":{"id":"AY_6OY4SMbAv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768493370619,"user_tz":360,"elapsed":109,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"c5f3a610-f188-4dc5-98f8-89c1d1894e44"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Manifest created: /content/run_20260115_155535_110b2989/run_manifest.json\n","‚úì Immutable log initialized: /content/run_20260115_155535_110b2989/logs/prompts_log.jsonl\n","‚úì Risk log initialized: /content/run_20260115_155535_110b2989/logs/risk_log.json\n","\n","Config Hash: 65e627a75fe8e195\n"]}]},{"cell_type":"markdown","source":["##5.PRIVACY PROTECTION"],"metadata":{"id":"aFfOfCZmMgx4"}},{"cell_type":"markdown","source":["###5.1.OVERVIEW"],"metadata":{"id":"tIlOMU-SMjni"}},{"cell_type":"markdown","source":["\n","\n","Cell 5 creates privacy protection tools that automatically remove sensitive personal information from any data that gets logged or stored. This is like having a smart redaction system that protects client confidentiality while still maintaining useful records for supervision.\n","\n","The cell defines a utility class called ConfidentialityUtils with two main functions. The first function, redact_prompt, scans through any text looking for patterns that might be personally identifiable information. It searches for Social Security Numbers in various formats, email addresses, phone numbers, and account numbers. When it finds these patterns, it replaces them with placeholder text like [SSN-REDACTED] or [EMAIL-REDACTED].\n","\n","Think of this function as an automatic highlighter that blacks out sensitive information before the text gets written to any log file. This ensures that even if someone gains access to the audit logs, they won't see actual client personal data. The patterns used are regular expressions - essentially search formulas that can identify things like \"three digits, dash, two digits, dash, four digits\" which matches SSN format.\n","\n","The second function, sanitize_case_data, takes any client scenario information and adds a clear warning label stating the data should be synthetic only. This serves as a constant reminder that real client information should never be pasted into the notebook.\n","\n","When you run this cell, you'll see a test demonstration showing how the redaction works. The test creates a sample text containing fake personal information - a Social Security Number, email address, phone number, and account number. The output shows the original text, then shows the same text after redaction, with all sensitive patterns replaced by generic placeholders. This visual proof helps you understand that the protection system is working correctly.\n","\n","These confidentiality utilities will be called automatically throughout the notebook whenever data needs to be logged. This means you don't have to remember to redact things manually - the system does it for you, reducing the risk of accidentally logging sensitive information. This is a critical governance control for using AI in financial advisory workflows where client privacy is paramount."],"metadata":{"id":"ksHvcArXMxMR"}},{"cell_type":"markdown","source":["###5.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"x7z8cMnQMx3g"}},{"cell_type":"code","source":["# Cell 5\n","# Goal: Implement confidentiality utilities for PII redaction\n","# Output: Test redaction examples showing utility functions work correctly\n","\n","import re\n","\n","class ConfidentialityUtils:\n","    \"\"\"Minimum-necessary redaction utilities\"\"\"\n","\n","    @staticmethod\n","    def redact_prompt(text: str) -> str:\n","        \"\"\"Redact PII patterns from prompts for logging\"\"\"\n","        # SSN patterns\n","        text = re.sub(r'\\b\\d{3}-\\d{2}-\\d{4}\\b', '[SSN-REDACTED]', text)\n","        text = re.sub(r'\\b\\d{9}\\b', '[SSN-REDACTED]', text)\n","\n","        # Email\n","        text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '[EMAIL-REDACTED]', text)\n","\n","        # Phone\n","        text = re.sub(r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b', '[PHONE-REDACTED]', text)\n","\n","        # Account numbers (8+ digits)\n","        text = re.sub(r'\\b\\d{8,}\\b', '[ACCOUNT-REDACTED]', text)\n","\n","        # Dollar amounts (keep for context but flag)\n","        # Not redacted but marked for review\n","\n","        return text\n","\n","    @staticmethod\n","    def sanitize_case_data(case_dict: Dict) -> Dict:\n","        \"\"\"Ensure case data is synthetic/sanitized\"\"\"\n","        sanitized = case_dict.copy()\n","        sanitized['_sanitization_note'] = \"Synthetic data only. Do not use real client PII.\"\n","        return sanitized\n","\n","# Test redaction\n","test_text = \"Client SSN is 123-45-6789, email john.doe@example.com, phone 555-123-4567, account 12345678\"\n","redacted = ConfidentialityUtils.redact_prompt(test_text)\n","\n","print(\"‚úì Confidentiality utilities loaded\")\n","print(f\"\\nRedaction test:\")\n","print(f\"Original: {test_text}\")\n","print(f\"Redacted: {redacted}\")"],"metadata":{"id":"_OdMQ8SwMiEp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768493372949,"user_tz":360,"elapsed":21,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"69f5e6a1-4b55-4541-e547-cd6b647fb2bd"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Confidentiality utilities loaded\n","\n","Redaction test:\n","Original: Client SSN is 123-45-6789, email john.doe@example.com, phone 555-123-4567, account 12345678\n","Redacted: Client SSN is [SSN-REDACTED], email [EMAIL-REDACTED], phone [PHONE-REDACTED], account [ACCOUNT-REDACTED]\n"]}]},{"cell_type":"markdown","source":["##6.LLM WRAPPER"],"metadata":{"id":"uVJjvhvVM0E8"}},{"cell_type":"markdown","source":["###6.1.OVERVIEW"],"metadata":{"id":"MyxD2F2XM1J3"}},{"cell_type":"markdown","source":["\n","\n","Cell 6 builds the intelligent wrapper that manages all communication with the Claude AI model. Think of this as creating a quality control inspector that stands between your workflow and the AI, ensuring every response meets strict standards before being accepted.\n","\n","The wrapper enforces a specific structure for all AI responses. Every agent must return information in exactly the same JSON format with ten required fields: task description, facts provided, assumptions made, alternatives considered, open questions, analysis notes, risks identified, draft output, verification status, and items needing verification. This standardization ensures consistency across all workflow steps and makes supervision much easier.\n","\n","When any agent calls the AI, this wrapper does several important things automatically. First, it enhances the instructions sent to the AI, explicitly requiring JSON-only responses with strict length limits to prevent truncation problems. The wrapper tells the AI to keep lists short (five to eight items maximum) and text fields brief (800 characters for drafts, 400 for analysis). These limits ensure responses complete without being cut off mid-sentence.\n","\n","The wrapper includes sophisticated error handling with retry logic. If the AI returns malformed JSON or the response gets truncated, the wrapper automatically tries again up to two times. It also strips out any markdown formatting that might have accidentally been included, cleaning the response before attempting to parse it as JSON.\n","\n","After successfully parsing the JSON, the wrapper validates that all required fields are present and runs security checks. It scans the text looking for dangerous patterns like implied investment recommendations, unauthorized suitability determinations, or invented regulatory citations. When these patterns are detected, the wrapper automatically logs them to the risk register so supervisors can review them later.\n","\n","The output confirms the wrapper is ready with multiple protection layers active. You'll see messages indicating the token limit, retry logic, length enforcement, truncation detection, and risk pattern detection are all operational. This comprehensive quality control system ensures the agentic workflow maintains high standards throughout execution while protecting against common AI output problems."],"metadata":{"id":"NbI8D2MMNp2V"}},{"cell_type":"markdown","source":["###6.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"HYi01MJHM25b"}},{"cell_type":"code","source":["# Cell 6\n","# Goal: Implement strict JSON LLM wrapper with validation and risk detection\n","# Output: LLM wrapper class ready for agent calls\n","\n","class StrictJSONLLMWrapper:\n","    \"\"\"Enforces structured output format with risk detection\"\"\"\n","\n","    REQUIRED_KEYS = [\n","        \"task\", \"facts_provided\", \"assumptions\", \"alternatives\",\n","        \"open_questions\", \"analysis\", \"risks\", \"draft_output\",\n","        \"verification_status\", \"questions_to_verify\"\n","    ]\n","\n","    RISK_TYPES = [\n","        \"confidentiality\", \"hallucination\", \"missing_facts\", \"suitability\",\n","        \"regbi\", \"conflicts\", \"liquidity\", \"prompt_injection\", \"overreach\", \"other\"\n","    ]\n","\n","    JSON_SCHEMA = \"\"\"{\n","  \"task\": \"brief description\",\n","  \"facts_provided\": [\"fact1\", \"fact2\"],\n","  \"assumptions\": [\"assumption1\", \"assumption2\"],\n","  \"alternatives\": [\"alternative1\"],\n","  \"open_questions\": [\"question1\", \"question2\"],\n","  \"analysis\": \"brief workflow notes\",\n","  \"risks\": [{\"type\": \"risk_type\", \"severity\": \"low|medium|high\", \"note\": \"brief note\"}],\n","  \"draft_output\": \"MUST start with disclaimer, then brief content\",\n","  \"verification_status\": \"Not verified\",\n","  \"questions_to_verify\": [\"item1\"]\n","}\"\"\"\n","\n","    def __init__(self, client: anthropic.Anthropic, logger):\n","        self.client = client\n","        self.logger = logger\n","\n","    def call(self, agent_name: str, system_prompt: str, user_prompt: str, step_id: str) -> Dict:\n","        \"\"\"Make LLM call with strict JSON validation\"\"\"\n","\n","        # Enhance system prompt with explicit JSON requirements\n","        enhanced_system = f\"\"\"{system_prompt}\n","\n","CRITICAL JSON REQUIREMENTS:\n","1. Respond with ONLY valid JSON - no preamble, no explanation\n","2. No markdown (no ```json or ```)\n","3. Keep responses CONCISE - token limit is strict\n","4. For lists: max 5-8 items each to avoid truncation\n","5. For draft_output: max 800 characters\n","6. For analysis: max 400 characters\n","7. Use this structure:\n","{self.JSON_SCHEMA}\n","\n","REQUIRED disclaimer start for draft_output:\n","\"NOT INVESTMENT, TAX, OR LEGAL ADVICE. Draft planning and communication assistance only. Qualified advisor review required.\"\n","\"\"\"\n","\n","        # Redact prompts for logging\n","        redacted_system = ConfidentialityUtils.redact_prompt(system_prompt[:500])\n","        redacted_user = ConfidentialityUtils.redact_prompt(user_prompt[:500])\n","\n","        max_retries = 2\n","        for attempt in range(max_retries):\n","            try:\n","                response = self.client.messages.create(\n","                    model=\"claude-sonnet-4-5-20250929\",\n","                    max_tokens=4096,  # INCREASED from 2500\n","                    temperature=0.2,\n","                    system=enhanced_system,\n","                    messages=[{\"role\": \"user\", \"content\": user_prompt}]\n","                )\n","\n","                response_text = response.content[0].text.strip()\n","\n","                # Remove markdown formatting\n","                if response_text.startswith(\"```json\"):\n","                    response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n","                elif response_text.startswith(\"```\"):\n","                    response_text = response_text.replace(\"```\", \"\").strip()\n","\n","                # Check for truncation indicators\n","                if response_text.endswith('\"') and response_text.count('{') == response_text.count('}'):\n","                    # Likely complete\n","                    pass\n","                elif not response_text.endswith('}'):\n","                    print(f\"‚ö†Ô∏è Response may be truncated (attempt {attempt + 1}/{max_retries})\")\n","                    if attempt < max_retries - 1:\n","                        continue  # Retry\n","\n","                # Parse JSON\n","                try:\n","                    parsed = json.loads(response_text)\n","                except json.JSONDecodeError as e:\n","                    print(f\"\\n‚ö†Ô∏è JSON PARSE ERROR in {agent_name} (attempt {attempt + 1}/{max_retries})\")\n","                    print(f\"Error: {str(e)}\")\n","                    print(f\"Response length: {len(response_text)} chars\")\n","                    print(f\"Response preview: {response_text[:500]}...\")\n","                    print(f\"Response end: ...{response_text[-200:]}\")\n","\n","                    if attempt < max_retries - 1:\n","                        print(\"  Retrying with more concise prompt...\")\n","                        continue\n","\n","                    self.logger.log_risk({\n","                        \"type\": \"non_json_response\",\n","                        \"severity\": \"high\",\n","                        \"note\": f\"Agent {agent_name} returned non-JSON after {max_retries} attempts: {str(e)}\",\n","                        \"step_id\": step_id\n","                    })\n","                    raise ValueError(f\"Non-JSON response from {agent_name}: {str(e)}\")\n","\n","                # Validate structure\n","                missing_keys = [k for k in self.REQUIRED_KEYS if k not in parsed]\n","                if missing_keys:\n","                    self.logger.log_risk({\n","                        \"type\": \"workflow_integrity_gap\",\n","                        \"severity\": \"high\",\n","                        \"note\": f\"Missing required keys: {missing_keys}\",\n","                        \"step_id\": step_id\n","                    })\n","                    raise ValueError(f\"Missing keys: {missing_keys}\")\n","\n","                # Ensure arrays are not empty\n","                for key in [\"facts_provided\", \"assumptions\", \"alternatives\", \"open_questions\", \"questions_to_verify\"]:\n","                    if not parsed.get(key):\n","                        parsed[key] = [\"None identified\"]\n","\n","                if not parsed.get(\"risks\"):\n","                    parsed[\"risks\"] = []\n","\n","                # Detect risk patterns\n","                self._detect_risks(parsed, agent_name, step_id)\n","\n","                # Log to immutable chain\n","                self.logger.log_prompt_response(\n","                    step_id=step_id,\n","                    agent_name=agent_name,\n","                    redacted_prompt=f\"{redacted_system[:200]}...{redacted_user[:200]}\",\n","                    redacted_response=ConfidentialityUtils.redact_prompt(response_text[:500])\n","                )\n","\n","                return parsed\n","\n","            except anthropic.APIError as e:\n","                print(f\"\\n‚ö†Ô∏è API ERROR in {agent_name}: {str(e)}\")\n","                if attempt < max_retries - 1:\n","                    print(\"  Retrying...\")\n","                    continue\n","                self.logger.log_risk({\n","                    \"type\": \"other\",\n","                    \"severity\": \"high\",\n","                    \"note\": f\"API call failed after {max_retries} attempts: {str(e)}\",\n","                    \"step_id\": step_id\n","                })\n","                raise\n","\n","        raise ValueError(f\"Failed to get valid JSON from {agent_name} after {max_retries} attempts\")\n","\n","    def _detect_risks(self, parsed: Dict, agent_name: str, step_id: str):\n","        \"\"\"Detect risk patterns in response\"\"\"\n","        draft = parsed.get(\"draft_output\", \"\").lower()\n","        analysis = parsed.get(\"analysis\", \"\").lower()\n","\n","        # Check for invented authority\n","        authority_patterns = [\n","            r'sec rule \\d+', r'finra rule \\d+', r'irc section \\d+',\n","            r'erisa section \\d+', r'according to sec', r'finra requires'\n","        ]\n","        for pattern in authority_patterns:\n","            if re.search(pattern, draft) or re.search(pattern, analysis):\n","                if parsed.get(\"verification_status\") != \"Not verified\":\n","                    self.logger.log_risk({\n","                        \"type\": \"invented_authority_detected\",\n","                        \"severity\": \"high\",\n","                        \"note\": f\"Authority pattern without 'Not verified' status in {agent_name}\",\n","                        \"step_id\": step_id\n","                    })\n","\n","        # Check for implied recommendations\n","        recommendation_patterns = [\n","            r'should invest', r'recommended allocation', r'buy\\s+\\w+\\s+stock',\n","            r'sell\\s+\\w+', r'we recommend', r'best choice is'\n","        ]\n","        for pattern in recommendation_patterns:\n","            if re.search(pattern, draft):\n","                self.logger.log_risk({\n","                    \"type\": \"implied_recommendation_detected\",\n","                    \"severity\": \"high\",\n","                    \"note\": f\"Recommendation language detected in {agent_name}\",\n","                    \"step_id\": step_id\n","                })\n","\n","        # Check for suitability determination language\n","        suitability_patterns = [r'is suitable', r'meets suitability', r'suitable for client']\n","        for pattern in suitability_patterns:\n","            if re.search(pattern, draft):\n","                self.logger.log_risk({\n","                    \"type\": \"implied_suitability_determination_detected\",\n","                    \"severity\": \"high\",\n","                    \"note\": f\"Suitability determination language in {agent_name}\",\n","                    \"step_id\": step_id\n","                })\n","\n","print(\"‚úì Strict JSON LLM wrapper loaded\")\n","print(\"‚úì Max tokens: 4096 with retry logic\")\n","print(\"‚úì Concise response enforcement (lists max 5-8 items)\")\n","print(\"‚úì Truncation detection and retry\")\n","print(\"‚úì Risk detection patterns active\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zN_Cz5nAapol","executionInfo":{"status":"ok","timestamp":1768493375325,"user_tz":360,"elapsed":10,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"ac979a8b-08c9-4f97-d711-a965b606ebce"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Strict JSON LLM wrapper loaded\n","‚úì Max tokens: 4096 with retry logic\n","‚úì Concise response enforcement (lists max 5-8 items)\n","‚úì Truncation detection and retry\n","‚úì Risk detection patterns active\n"]}]},{"cell_type":"markdown","source":["##7.MINI CASE BUILDERS"],"metadata":{"id":"Dr34h4v4M8SU"}},{"cell_type":"markdown","source":["###7.1.OVERVIEW"],"metadata":{"id":"EnAuC2ckM_GU"}},{"cell_type":"markdown","source":["\n","\n","Cell 7 creates all the specialized agents and infrastructure needed to run the multi-step advisory workflow. Think of this as assembling a team of focused assistants, each with a specific job, along with the shared systems they'll use to coordinate their work.\n","\n","The cell first builds the Logger class, which maintains the tamper-evident audit trail. Every time an agent interacts with the AI, the logger records it with cryptographic hashing. Each new log entry includes a hash of the previous entry, creating a mathematical chain. If anyone tried to alter a past entry, the chain would break, immediately revealing the tampering. This is the same principle used in blockchain technology.\n","\n","Next comes the SharedState class, which acts as the workflow's memory and coordination center. It maintains four critical registers: assumptions made during analysis, open items requiring follow-up, claims needing external verification, and a history of all checkpoint approvals. The state also includes the checkpoint mechanism, which can pause the workflow requiring human review before proceeding. Additionally, it has logic to check for unresolved hinge facts - critical assumptions that must be validated before downstream work continues.\n","\n","The cell then creates six specialized agent classes. The IntakeAgent structures raw client scenarios into organized facts, assumptions, and questions. The IPSDraftAgent generates Investment Policy Statement shells focusing on process and governance without specifying investments. The DisclosureAgent creates checklists of topics advisors should disclose to clients. The SuitabilityReasoningAgent drafts structured questions advisors must answer when evaluating strategies, explicitly avoiding any suitability conclusions. The QCReviewerAgent examines all previous work looking for gaps, inconsistencies, or missing information. Finally, the RiskAssessorAgent evaluates the overall workflow for integrity problems.\n","\n","Each agent is programmed with explicit instructions to keep responses concise and structured. The prompts specify maximum item counts and character limits to prevent the truncation problems encountered earlier. For example, agents are told to list only five to eight key facts, keep analysis to 300-400 characters, and limit draft outputs to 800 characters.\n","\n","The confirmation message lists all loaded components, emphasizing that every agent enforces strict JSON-only responses with concise formatting to ensure reliability."],"metadata":{"id":"EKvlFydjNrmX"}},{"cell_type":"markdown","source":["###7.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"X1KSLRldNBYW"}},{"cell_type":"code","source":["# Cell 7\n","# Goal: Implement agent classes with CONCISE prompts to avoid truncation\n","# Output: All agent classes ready\n","\n","class Logger:\n","    \"\"\"Immutable audit trail with hash chaining\"\"\"\n","\n","    def __init__(self, logs_dir: Path):\n","        self.logs_dir = logs_dir\n","        self.prompts_log_path = logs_dir / \"prompts_log.jsonl\"\n","        self.risk_log_path = logs_dir / \"risk_log.json\"\n","        self.last_hash = \"0\" * 64\n","\n","        if self.prompts_log_path.exists():\n","            with open(self.prompts_log_path, \"r\") as f:\n","                lines = f.readlines()\n","                if lines:\n","                    last_entry = json.loads(lines[-1])\n","                    self.last_hash = last_entry.get(\"response_hash\", \"0\" * 64)\n","\n","    def log_prompt_response(self, step_id: str, agent_name: str,\n","                           redacted_prompt: str, redacted_response: str):\n","        \"\"\"Append to immutable log with hash chaining\"\"\"\n","        prompt_hash = hashlib.sha256(redacted_prompt.encode()).hexdigest()\n","        response_hash = hashlib.sha256(redacted_response.encode()).hexdigest()\n","\n","        entry = {\n","            \"step_id\": step_id,\n","            \"timestamp\": datetime.now().isoformat(),\n","            \"agent_name\": agent_name,\n","            \"prompt_hash\": prompt_hash,\n","            \"response_hash\": response_hash,\n","            \"prev_hash\": self.last_hash,\n","            \"redacted_prompt\": redacted_prompt,\n","            \"redacted_response\": redacted_response\n","        }\n","\n","        with open(self.prompts_log_path, \"a\") as f:\n","            f.write(json.dumps(entry) + \"\\n\")\n","\n","        self.last_hash = response_hash\n","\n","    def log_risk(self, risk_entry: Dict):\n","        \"\"\"Append to risk log\"\"\"\n","        risk_entry[\"timestamp\"] = datetime.now().isoformat()\n","\n","        with open(self.risk_log_path, \"r\") as f:\n","            risk_log = json.load(f)\n","\n","        risk_log[\"risks\"].append(risk_entry)\n","\n","        with open(self.risk_log_path, \"w\") as f:\n","            json.dump(risk_log, f, indent=2)\n","\n","\n","class SharedState:\n","    \"\"\"Workflow state with registers and checkpoint tracking\"\"\"\n","\n","    def __init__(self, run_id: str):\n","        self.run_id = run_id\n","        self.cases = {}\n","        self.assumption_register = {}\n","        self.open_items_register = {}\n","        self.not_verified_register = {}\n","        self.checkpoint_history = []\n","\n","    def add_case(self, case_id: str, case_data: Dict):\n","        self.cases[case_id] = {\n","            \"data\": ConfidentialityUtils.sanitize_case_data(case_data),\n","            \"artifacts\": {},\n","            \"status\": \"initialized\"\n","        }\n","\n","    def add_assumption(self, case_id: str, assumption: str, is_hinge_fact: bool = False):\n","        if case_id not in self.assumption_register:\n","            self.assumption_register[case_id] = []\n","        self.assumption_register[case_id].append({\n","            \"assumption\": assumption,\n","            \"is_hinge_fact\": is_hinge_fact,\n","            \"resolved\": False\n","        })\n","\n","    def add_open_item(self, case_id: str, item: str):\n","        if case_id not in self.open_items_register:\n","            self.open_items_register[case_id] = []\n","        self.open_items_register[case_id].append(item)\n","\n","    def add_not_verified(self, case_id: str, item: str):\n","        if case_id not in self.not_verified_register:\n","            self.not_verified_register[case_id] = []\n","        self.not_verified_register[case_id].append(item)\n","\n","    def checkpoint(self, checkpoint_name: str, case_id: str, auto_approve: bool = False) -> bool:\n","        \"\"\"Human approval gate\"\"\"\n","        checkpoint_entry = {\n","            \"checkpoint_name\": checkpoint_name,\n","            \"case_id\": case_id,\n","            \"timestamp\": datetime.now().isoformat(),\n","            \"auto_approve\": auto_approve,\n","            \"approved\": auto_approve\n","        }\n","        self.checkpoint_history.append(checkpoint_entry)\n","\n","        if not auto_approve:\n","            print(f\"\\nüõë CHECKPOINT: {checkpoint_name} (Case: {case_id})\")\n","\n","        return checkpoint_entry[\"approved\"]\n","\n","    def check_hinge_facts(self, case_id: str, logger: Logger) -> bool:\n","        \"\"\"Block if hinge facts unresolved\"\"\"\n","        assumptions = self.assumption_register.get(case_id, [])\n","        unresolved_hinge = [a for a in assumptions if a[\"is_hinge_fact\"] and not a[\"resolved\"]]\n","\n","        if unresolved_hinge:\n","            logger.log_risk({\n","                \"type\": \"hinge_fact_unresolved_block\",\n","                \"severity\": \"high\",\n","                \"note\": f\"Unresolved hinge facts: {len(unresolved_hinge)} items\",\n","                \"case_id\": case_id\n","            })\n","            return False\n","        return True\n","\n","\n","class IntakeAgent:\n","    \"\"\"Structures client scenarios\"\"\"\n","\n","    def __init__(self, llm: StrictJSONLLMWrapper):\n","        self.llm = llm\n","\n","    def process(self, case_id: str, raw_scenario: str) -> Dict:\n","        system = \"\"\"Intake agent: extract facts, identify assumptions, flag unknowns.\n","Return valid JSON only. Keep lists to 5-8 items max.\"\"\"\n","\n","        user = f\"\"\"Extract key info from this scenario. Be CONCISE.\n","\n","{raw_scenario}\n","\n","Return JSON with:\n","- task: Brief description\n","- facts_provided: 5-8 KEY facts only (age, assets, goals)\n","- assumptions: 3-5 key assumptions\n","- alternatives: 2-3 alternatives\n","- open_questions: 3-5 critical questions\n","- analysis: 2-3 sentences on intake (max 400 chars)\n","- risks: 1-3 risks\n","- draft_output: Brief summary starting with: \"NOT INVESTMENT, TAX, OR LEGAL ADVICE. Draft planning and communication assistance only. Qualified advisor review required.\" Then 3-4 sentences. Max 800 chars total.\n","- verification_status: \"Not verified\"\n","- questions_to_verify: 2-4 items\n","\n","JSON only. No other text.\"\"\"\n","\n","        return self.llm.call(\"IntakeAgent\", system, user, f\"{case_id}_intake\")\n","\n","\n","class IPSDraftAgent:\n","    \"\"\"Generates IPS shells\"\"\"\n","\n","    def __init__(self, llm: StrictJSONLLMWrapper):\n","        self.llm = llm\n","\n","    def process(self, case_id: str, intake_result: Dict) -> Dict:\n","        system = \"\"\"IPS shell drafter. NO allocations/targets. Return valid JSON only.\"\"\"\n","\n","        facts_str = \"; \".join(intake_result.get(\"facts_provided\", [])[:5])\n","\n","        user = f\"\"\"Draft IPS shell. Be CONCISE.\n","\n","Key facts: {facts_str}\n","\n","Return JSON with:\n","- task: \"Draft IPS shell\"\n","- facts_provided: 3-5 key facts\n","- assumptions: 2-3 assumptions\n","- alternatives: 2-3 IPS approaches\n","- open_questions: 2-4 questions\n","- analysis: 2 sentences (max 300 chars)\n","- risks: 1-2 risks\n","- draft_output: Start with disclaimer, then IPS sections (Purpose, Roles, Process, Review). Max 800 chars.\n","- verification_status: \"Not verified\"\n","- questions_to_verify: 2-3 items\n","\n","JSON only.\"\"\"\n","\n","        return self.llm.call(\"IPSDraftAgent\", system, user, f\"{case_id}_ips\")\n","\n","\n","class DisclosureAgent:\n","    \"\"\"Builds disclosure checklists\"\"\"\n","\n","    def __init__(self, llm: StrictJSONLLMWrapper):\n","        self.llm = llm\n","\n","    def process(self, case_id: str, intake_result: Dict) -> Dict:\n","        system = \"\"\"Disclosure checklist creator. Return valid JSON only.\"\"\"\n","\n","        facts_str = \"; \".join(intake_result.get(\"facts_provided\", [])[:5])\n","\n","        user = f\"\"\"Create disclosure checklist. Be CONCISE.\n","\n","Facts: {facts_str}\n","\n","Return JSON with:\n","- task: \"Disclosure checklist\"\n","- facts_provided: 3-4 key facts\n","- assumptions: 2-3 assumptions\n","- alternatives: 2 alternative approaches\n","- open_questions: 2-3 questions\n","- analysis: 2 sentences (max 300 chars)\n","- risks: 1-3 disclosure risks\n","- draft_output: Start with disclaimer, then checklist (compensation, conflicts, risks, limitations). Max 800 chars.\n","- verification_status: \"Not verified\"\n","- questions_to_verify: 2-3 items\n","\n","JSON only.\"\"\"\n","\n","        return self.llm.call(\"DisclosureAgent\", system, user, f\"{case_id}_disclosure\")\n","\n","\n","class SuitabilityReasoningAgent:\n","    \"\"\"Drafts suitability scaffolds\"\"\"\n","\n","    def __init__(self, llm: StrictJSONLLMWrapper):\n","        self.llm = llm\n","\n","    def process(self, case_id: str, intake_result: Dict) -> Dict:\n","        system = \"\"\"Suitability reasoning scaffold. NEVER conclude suitable/unsuitable. JSON only.\"\"\"\n","\n","        facts_str = \"; \".join(intake_result.get(\"facts_provided\", [])[:5])\n","\n","        user = f\"\"\"Draft suitability scaffold. Be CONCISE.\n","\n","Facts: {facts_str}\n","\n","Return JSON with:\n","- task: \"Suitability reasoning scaffold\"\n","- facts_provided: 3-4 key profile facts\n","- assumptions: 2-3 assumptions\n","- alternatives: 2-3 strategies to compare\n","- open_questions: 3-5 suitability questions\n","- analysis: 2 sentences (max 300 chars)\n","- risks: 1-3 suitability risks\n","- draft_output: Start with disclaimer, then questions advisor must answer (client info needed? alternatives? risks? conflicts? docs?). Max 800 chars.\n","- verification_status: \"Not verified\"\n","- questions_to_verify: 2-3 Reg BI items\n","\n","JSON only.\"\"\"\n","\n","        return self.llm.call(\"SuitabilityReasoningAgent\", system, user, f\"{case_id}_suitability\")\n","\n","\n","class QCReviewerAgent:\n","    \"\"\"Flags workflow gaps\"\"\"\n","\n","    def __init__(self, llm: StrictJSONLLMWrapper):\n","        self.llm = llm\n","\n","    def process(self, case_id: str, all_artifacts: Dict) -> Dict:\n","        system = \"\"\"QC reviewer. Flag gaps/inconsistencies. JSON only.\"\"\"\n","\n","        artifact_count = len(all_artifacts)\n","\n","        user = f\"\"\"QC review {artifact_count} artifacts. Be CONCISE.\n","\n","Return JSON with:\n","- task: \"QC review\"\n","- facts_provided: 2-3 key findings\n","- assumptions: 2 QC assumptions\n","- alternatives: 1-2 QC approaches\n","- open_questions: 2-3 follow-up items\n","- analysis: 2 sentences (max 300 chars)\n","- risks: 2-4 gaps/inconsistencies\n","- draft_output: Start with disclaimer, then QC notes (missing info, inconsistencies, follow-up needed). Max 800 chars.\n","- verification_status: \"Not verified\"\n","- questions_to_verify: 2-3 items\n","\n","JSON only.\"\"\"\n","\n","        return self.llm.call(\"QCReviewerAgent\", system, user, f\"{case_id}_qc\")\n","\n","\n","class RiskAssessorAgent:\n","    \"\"\"Evaluates workflow risks\"\"\"\n","\n","    def __init__(self, llm: StrictJSONLLMWrapper):\n","        self.llm = llm\n","\n","    def process(self, case_id: str, state: SharedState) -> Dict:\n","        system = \"\"\"Workflow risk assessor. JSON only.\"\"\"\n","\n","        assumptions_count = len(state.assumption_register.get(case_id, []))\n","        open_items_count = len(state.open_items_register.get(case_id, []))\n","\n","        user = f\"\"\"Assess workflow risks. Be CONCISE.\n","\n","Assumptions: {assumptions_count}, Open items: {open_items_count}\n","\n","Return JSON with:\n","- task: \"Workflow risk assessment\"\n","- facts_provided: 2-3 workflow state facts\n","- assumptions: 2 assumptions\n","- alternatives: 1-2 mitigation approaches\n","- open_questions: 2-3 escalation items\n","- analysis: 2 sentences (max 300 chars)\n","- risks: 2-4 workflow integrity risks\n","- draft_output: Start with disclaimer, then risk summary. Max 800 chars.\n","- verification_status: \"Not verified\"\n","- questions_to_verify: 2-3 items\n","\n","JSON only.\"\"\"\n","\n","        return self.llm.call(\"RiskAssessorAgent\", system, user, f\"{case_id}_risk_assessment\")\n","\n","\n","print(\"‚úì Agent classes loaded with CONCISE prompts\")\n","print(\"‚úì All responses limited to prevent truncation\")\n","print(\"‚úì Lists: 2-8 items max\")\n","print(\"‚úì draft_output: 800 chars max\")\n","print(\"‚úì analysis: 300-400 chars max\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tn-SMwhwauKk","executionInfo":{"status":"ok","timestamp":1768493378304,"user_tz":360,"elapsed":9,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"b4121db4-2306-4de9-fbe1-14b6030ab56a"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Agent classes loaded with CONCISE prompts\n","‚úì All responses limited to prevent truncation\n","‚úì Lists: 2-8 items max\n","‚úì draft_output: 800 chars max\n","‚úì analysis: 300-400 chars max\n"]}]},{"cell_type":"markdown","source":["##8.THE ORCHESTRATOR AGENT"],"metadata":{"id":"E9DiNZg2NOyv"}},{"cell_type":"markdown","source":["###8.1.OVERVIEW"],"metadata":{"id":"Ee1sdukLNP3S"}},{"cell_type":"markdown","source":["\n","Cell 8 builds the OrchestratorAgent, which acts as the conductor coordinating all other agents through a structured multi-step workflow. Think of this as the project manager who ensures work happens in the right sequence, with proper quality checks at each stage.\n","\n","The orchestrator maintains references to all the specialized agents created in Cell 7, along with access to the shared state and logging systems. When asked to execute a workflow for a specific case, it follows a rigorous six-step process with built-in checkpoints.\n","\n","The workflow begins with Step 1 where the IntakeAgent analyzes the raw client scenario. The orchestrator captures the intake results, then systematically registers all assumptions, open questions, and items needing verification into the shared state. It also identifies which assumptions are \"hinge facts\" - critical pieces of information that must be validated before proceeding. After intake completes, Checkpoint 1 requires review before continuing. The orchestrator then verifies all hinge facts are resolved; if not, it blocks further progress and stops the workflow.\n","\n","Assuming clearance, Step 2 generates an IPS shell using the IPSDraftAgent, Step 3 creates disclosure checklists with the DisclosureAgent, and Step 4 builds suitability reasoning scaffolds with the SuitabilityReasoningAgent. After these drafting steps, Checkpoint 2 pauses for review of all draft materials.\n","\n","Step 5 applies the QCReviewerAgent to examine all artifacts for gaps and inconsistencies. Step 6 uses the RiskAssessorAgent to evaluate overall workflow integrity. After risk assessment, a Final Checkpoint requires approval before the package is considered ready for delivery.\n","\n","Throughout execution, the orchestrator prints status updates showing progress through each step. It reports how many facts, assumptions, and questions were identified, and how many risks were flagged. When checkpoints are reached, clear messages indicate human review is required.\n","\n","The finalize function saves all artifacts, registers, and checkpoint history to organized folders within the deliverables directory. Each case gets its own subfolder containing three JSON files: one with all agent outputs, one with the three registers, and one with checkpoint history.\n","\n","The confirmation shows the orchestrator is ready with the complete six-step workflow sequence and three checkpoint gates operational."],"metadata":{"id":"UPGXnne7NtGW"}},{"cell_type":"markdown","source":["###8.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"BIE5Ni_wNRvq"}},{"cell_type":"code","source":["# Cell 8\n","# Goal: Implement orchestrator state machine for multi-step workflows\n","# Output: Orchestrator ready to execute case workflows\n","\n","class OrchestratorAgent:\n","    \"\"\"Multi-step workflow state machine with checkpoint enforcement\"\"\"\n","\n","    def __init__(self, state: SharedState, logger: Logger, llm: StrictJSONLLMWrapper):\n","        self.state = state\n","        self.logger = logger\n","        self.llm = llm\n","\n","        # Initialize agent instances\n","        self.intake_agent = IntakeAgent(llm)\n","        self.ips_agent = IPSDraftAgent(llm)\n","        self.disclosure_agent = DisclosureAgent(llm)\n","        self.suitability_agent = SuitabilityReasoningAgent(llm)\n","        self.qc_agent = QCReviewerAgent(llm)\n","        self.risk_agent = RiskAssessorAgent(llm)\n","\n","    def execute_workflow(self, case_id: str, scenario: str) -> Dict:\n","        \"\"\"Execute full agentic workflow with checkpoints\"\"\"\n","\n","        print(f\"\\n{'='*60}\")\n","        print(f\"CASE: {case_id}\")\n","        print(f\"{'='*60}\")\n","\n","        # Initialize case\n","        self.state.add_case(case_id, {\"scenario\": scenario})\n","\n","        # STEP 1: Intake\n","        print(f\"\\nüîÑ Step 1: Intake & Structuring\")\n","        intake_result = self.intake_agent.process(case_id, scenario)\n","        self.state.cases[case_id][\"artifacts\"][\"intake\"] = intake_result\n","\n","        # Register assumptions and open items\n","        for assumption in intake_result.get(\"assumptions\", []):\n","            is_hinge = \"critical\" in assumption.lower() or \"must\" in assumption.lower()\n","            self.state.add_assumption(case_id, assumption, is_hinge)\n","\n","        for item in intake_result.get(\"open_questions\", []):\n","            self.state.add_open_item(case_id, item)\n","\n","        for item in intake_result.get(\"questions_to_verify\", []):\n","            self.state.add_not_verified(case_id, item)\n","\n","        print(f\"‚úì Intake complete\")\n","        print(f\"  Facts: {len(intake_result.get('facts_provided', []))}\")\n","        print(f\"  Assumptions: {len(intake_result.get('assumptions', []))}\")\n","        print(f\"  Open questions: {len(intake_result.get('open_questions', []))}\")\n","\n","        # CHECKPOINT 1: Review intake\n","        if not self.state.checkpoint(f\"Intake Review - {case_id}\", case_id, auto_approve=True):\n","            print(\"‚ùå Checkpoint not approved. Workflow stopped.\")\n","            return self._finalize_case(case_id, \"stopped_at_checkpoint_1\")\n","\n","        # Check hinge facts\n","        if not self.state.check_hinge_facts(case_id, self.logger):\n","            print(\"‚ö†Ô∏è Hinge facts unresolved. Blocking downstream drafting.\")\n","            return self._finalize_case(case_id, \"blocked_hinge_facts\")\n","\n","        # STEP 2: IPS Draft\n","        print(f\"\\nüîÑ Step 2: IPS Shell Drafting\")\n","        ips_result = self.ips_agent.process(case_id, intake_result)\n","        self.state.cases[case_id][\"artifacts\"][\"ips\"] = ips_result\n","        print(f\"‚úì IPS shell drafted\")\n","\n","        # STEP 3: Disclosure Checklist\n","        print(f\"\\nüîÑ Step 3: Disclosure Checklist\")\n","        disclosure_result = self.disclosure_agent.process(case_id, intake_result)\n","        self.state.cases[case_id][\"artifacts\"][\"disclosure\"] = disclosure_result\n","        print(f\"‚úì Disclosure checklist created\")\n","\n","        # STEP 4: Suitability Reasoning\n","        print(f\"\\nüîÑ Step 4: Suitability Reasoning Scaffold\")\n","        suitability_result = self.suitability_agent.process(case_id, intake_result)\n","        self.state.cases[case_id][\"artifacts\"][\"suitability\"] = suitability_result\n","        print(f\"‚úì Reasoning scaffold drafted\")\n","\n","        # CHECKPOINT 2: Review drafts\n","        if not self.state.checkpoint(f\"Draft Review - {case_id}\", case_id, auto_approve=True):\n","            print(\"‚ùå Checkpoint not approved. Workflow stopped.\")\n","            return self._finalize_case(case_id, \"stopped_at_checkpoint_2\")\n","\n","        # STEP 5: QC Review\n","        print(f\"\\nüîÑ Step 5: QC Review\")\n","        qc_result = self.qc_agent.process(case_id, self.state.cases[case_id][\"artifacts\"])\n","        self.state.cases[case_id][\"artifacts\"][\"qc\"] = qc_result\n","        print(f\"‚úì QC review complete\")\n","        print(f\"  Risks flagged: {len(qc_result.get('risks', []))}\")\n","\n","        # STEP 6: Risk Assessment\n","        print(f\"\\nüîÑ Step 6: Workflow Risk Assessment\")\n","        risk_result = self.risk_agent.process(case_id, self.state)\n","        self.state.cases[case_id][\"artifacts\"][\"risk_assessment\"] = risk_result\n","        print(f\"‚úì Risk assessment complete\")\n","\n","        # FINAL CHECKPOINT: Approve for delivery\n","        if not self.state.checkpoint(f\"Final Approval - {case_id}\", case_id, auto_approve=True):\n","            print(\"‚ùå Checkpoint not approved. Deliverables not finalized.\")\n","            return self._finalize_case(case_id, \"stopped_at_final_checkpoint\")\n","\n","        # Finalize\n","        return self._finalize_case(case_id, \"completed\")\n","\n","    def _finalize_case(self, case_id: str, status: str) -> Dict:\n","        \"\"\"Finalize case artifacts and save to deliverables folder\"\"\"\n","        self.state.cases[case_id][\"status\"] = status\n","\n","        case_deliverables_dir = DELIVERABLES_DIR / case_id\n","        case_deliverables_dir.mkdir(exist_ok=True)\n","\n","        # Save artifacts\n","        artifacts_path = case_deliverables_dir / \"artifacts.json\"\n","        with open(artifacts_path, \"w\") as f:\n","            json.dump(self.state.cases[case_id][\"artifacts\"], f, indent=2)\n","\n","        # Save registers\n","        registers_path = case_deliverables_dir / \"registers.json\"\n","        registers = {\n","            \"assumptions\": self.state.assumption_register.get(case_id, []),\n","            \"open_items\": self.state.open_items_register.get(case_id, []),\n","            \"not_verified\": self.state.not_verified_register.get(case_id, [])\n","        }\n","        with open(registers_path, \"w\") as f:\n","            json.dump(registers, f, indent=2)\n","\n","        # Save checkpoint history\n","        checkpoints_path = case_deliverables_dir / \"checkpoints.json\"\n","        case_checkpoints = [c for c in self.state.checkpoint_history if c[\"case_id\"] == case_id]\n","        with open(checkpoints_path, \"w\") as f:\n","            json.dump({\"checkpoints\": case_checkpoints}, f, indent=2)\n","\n","        print(f\"\\n‚úÖ Case finalized: {status}\")\n","        print(f\"üìÅ Deliverables saved: {case_deliverables_dir}\")\n","\n","        return {\n","            \"case_id\": case_id,\n","            \"status\": status,\n","            \"artifacts_path\": str(artifacts_path),\n","            \"registers_path\": str(registers_path),\n","            \"checkpoints_path\": str(checkpoints_path)\n","        }\n","\n","print(\"‚úì Orchestrator state machine loaded\")\n","print(\"‚úì Workflow steps: Intake ‚Üí IPS ‚Üí Disclosure ‚Üí Suitability ‚Üí QC ‚Üí Risk\")\n","print(\"‚úì Checkpoints: Post-intake, Post-drafts, Final approval\")"],"metadata":{"id":"GF7UbU5xNTWW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768493381469,"user_tz":360,"elapsed":223,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"588376ee-56d3-44a7-cc1b-945b03566b6e"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Orchestrator state machine loaded\n","‚úì Workflow steps: Intake ‚Üí IPS ‚Üí Disclosure ‚Üí Suitability ‚Üí QC ‚Üí Risk\n","‚úì Checkpoints: Post-intake, Post-drafts, Final approval\n"]}]},{"cell_type":"markdown","source":["##9.EXECUTION"],"metadata":{"id":"3juVsof2NUJC"}},{"cell_type":"markdown","source":["###9.1.OVERVIEW"],"metadata":{"id":"0A7X8eAeNVjp"}},{"cell_type":"markdown","source":["\n","\n","Cell 9 executes the complete agentic workflow for four different financial advisory scenarios, demonstrating the system in action. This is where you'll see all the infrastructure from previous cells working together to process real-world advisory situations.\n","\n","The cell first initializes all the components: the logger for audit trails, the shared state for workflow coordination, the LLM wrapper for AI communication, and the orchestrator to manage the process. Then it defines four synthetic client scenarios representing common advisory situations.\n","\n","Case 1 involves retirement distribution planning for a 64-year-old with 1.5 million dollars in assets, exploring questions about distribution strategies, tax efficiency, Social Security timing, and sequence-of-returns risk management. Case 2 addresses concentrated stock position diversification for a 45-year-old tech executive with 2 million dollars in employer stock, examining tax-efficient diversification approaches. Case 3 explores alternative investments for a high-net-worth couple interested in private equity and private credit, focusing on liquidity considerations. Case 4 presents a practice management training scenario where a junior advisor conducts their first client review, including how to handle out-of-scope requests.\n","\n","For each case, the orchestrator executes the full six-step workflow with checkpoints. You'll see detailed console output showing progress through each stage: intake structuring, IPS drafting, disclosure checklist creation, suitability reasoning, QC review, and risk assessment. The output includes statistics like how many facts were extracted, assumptions identified, and risks flagged.\n","\n","As the workflow runs, you might see warnings if any issues arise, such as JSON parsing problems or detected risk patterns. The system automatically logs these to the risk register. If a case encounters an unrecoverable error, it's marked as failed and execution continues with the next case.\n","\n","At completion, a summary table shows the final status of all four cases - which completed successfully, which failed, and why. This execution phase typically takes several minutes as each case involves multiple AI calls and quality checks. The result is a complete set of governance artifacts for each scenario, ready for advisor review and inclusion in supervision files."],"metadata":{"id":"7SgqchOZNupJ"}},{"cell_type":"markdown","source":["###9.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"q65FZs56NXZp"}},{"cell_type":"code","source":["# Cell 9\n","# Goal: Execute 4 mini-case demonstrations\n","# Output: Complete workflow execution for all 4 cases with deliverables\n","\n","# Initialize infrastructure\n","logger = Logger(LOGS_DIR)\n","state = SharedState(RUN_ID)\n","llm_wrapper = StrictJSONLLMWrapper(client, logger)\n","orchestrator = OrchestratorAgent(state, logger, llm_wrapper)\n","\n","# Define 4 mini-cases\n","CASES = {\n","    \"case_01_retirement\": \"\"\"\n","Client Profile (SYNTHETIC DATA ONLY):\n","- Age 64, plans to retire at 65\n","- Current portfolio: $1.2M in 401(k), $300K in taxable account\n","- Desired income: $80K/year\n","- Pension: $24K/year starting at 65\n","- Social Security: Considering delaying to age 70\n","- Risk tolerance: Moderate, concerned about sequence-of-returns risk\n","- Health: Good, family history of longevity\n","- Goals: Maintain lifestyle, travel, leave legacy to grandchildren\n","\n","Questions:\n","- What distribution strategy should be considered?\n","- How to structure accounts for tax efficiency?\n","- When to begin Social Security?\n","- How to manage sequence risk in early retirement?\n","\"\"\",\n","\n","    \"case_02_concentrated_stock\": \"\"\"\n","Client Profile (SYNTHETIC DATA ONLY):\n","- Age 45, tech executive\n","- $2M concentrated position in employer stock (60% of net worth)\n","- Unvested RSUs: $800K over next 3 years\n","- Other assets: $500K in diversified accounts\n","- Tax basis in stock: $300K (long-term gains)\n","- Goals: Diversify without triggering large tax hit, maintain upside exposure\n","- Risk tolerance: Aggressive, but concerned about concentration\n","- Time horizon: 20+ years to retirement\n","\n","Questions:\n","- How to structure diversification strategy?\n","- Tax-efficient vehicles to consider?\n","- Hedging strategies if appropriate?\n","- How to balance diversification goals with tax impact?\n","\"\"\",\n","\n","    \"case_03_alternatives\": \"\"\"\n","Client Profile (SYNTHETIC DATA ONLY):\n","- High-net-worth couple, ages 52 and 50\n","- Liquid portfolio: $8M\n","- Interested in alternatives: private equity, private credit, real assets\n","- Current allocation: 70% equity, 25% fixed income, 5% cash\n","- Risk tolerance: Moderate-aggressive\n","- Liquidity needs: $150K/year for 10 years, then retirement income\n","- Goals: Diversification, inflation protection, higher returns\n","\n","Questions:\n","- What proportion of alternatives is appropriate given liquidity needs?\n","- Lock-up periods and liquidity considerations?\n","- Due diligence requirements for alternative investments?\n","- How to structure and monitor illiquid positions?\n","- Fee structures and transparency concerns?\n","\"\"\",\n","\n","    \"case_04_practice_mgmt\": \"\"\"\n","Practice Management Training Scenario (SYNTHETIC DATA ONLY):\n","\n","New advisor training case:\n","- Junior advisor conducting first full client review\n","- Client is a 58-year-old small business owner\n","- Portfolio review shows drift from IPS targets\n","- Client asking about crypto allocation (read online article)\n","- Client also mentions friend's concentrated stock success\n","- Compliance note: Firm does not currently custody crypto\n","\n","Training objectives:\n","- How to structure client meeting agenda?\n","- How to document recommendations vs. client requests?\n","- What compliance checkpoints are needed?\n","- How to address rebalancing recommendations?\n","- How to handle out-of-scope requests (crypto)?\n","- What supervision is required before implementation?\n","\"\"\"\n","}\n","\n","# Execute all cases\n","results = {}\n","for case_id, scenario in CASES.items():\n","    try:\n","        result = orchestrator.execute_workflow(case_id, scenario)\n","        results[case_id] = result\n","    except Exception as e:\n","        print(f\"\\n‚ùå Error in {case_id}: {str(e)}\")\n","        logger.log_risk({\n","            \"type\": \"other\",\n","            \"severity\": \"high\",\n","            \"note\": f\"Workflow execution failed for {case_id}: {str(e)}\",\n","            \"case_id\": case_id\n","        })\n","        results[case_id] = {\"status\": \"failed\", \"error\": str(e)}\n","\n","print(f\"\\n{'='*60}\")\n","print(f\"ALL CASES COMPLETE\")\n","print(f\"{'='*60}\")\n","for case_id, result in results.items():\n","    status_icon = \"‚úÖ\" if result.get(\"status\") == \"completed\" else \"‚ö†Ô∏è\"\n","    print(f\"{status_icon} {case_id}: {result.get('status', 'unknown')}\")"],"metadata":{"id":"h8-UJrsrNZmu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768493709035,"user_tz":360,"elapsed":322950,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"bd227eae-d1e2-4c3f-931d-879447b2b31c"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","CASE: case_01_retirement\n","============================================================\n","\n","üîÑ Step 1: Intake & Structuring\n","‚úì Intake complete\n","  Facts: 7\n","  Assumptions: 4\n","  Open questions: 5\n","\n","üîÑ Step 2: IPS Shell Drafting\n","‚úì IPS shell drafted\n","\n","üîÑ Step 3: Disclosure Checklist\n","‚úì Disclosure checklist created\n","\n","üîÑ Step 4: Suitability Reasoning Scaffold\n","‚úì Reasoning scaffold drafted\n","\n","üîÑ Step 5: QC Review\n","‚úì QC review complete\n","  Risks flagged: 4\n","\n","üîÑ Step 6: Workflow Risk Assessment\n","‚úì Risk assessment complete\n","\n","‚úÖ Case finalized: completed\n","üìÅ Deliverables saved: /content/run_20260115_155535_110b2989/deliverables/case_01_retirement\n","\n","============================================================\n","CASE: case_02_concentrated_stock\n","============================================================\n","\n","üîÑ Step 1: Intake & Structuring\n","‚úì Intake complete\n","  Facts: 5\n","  Assumptions: 5\n","  Open questions: 5\n","\n","üîÑ Step 2: IPS Shell Drafting\n","‚úì IPS shell drafted\n","\n","üîÑ Step 3: Disclosure Checklist\n","‚úì Disclosure checklist created\n","\n","üîÑ Step 4: Suitability Reasoning Scaffold\n","‚úì Reasoning scaffold drafted\n","\n","üîÑ Step 5: QC Review\n","‚úì QC review complete\n","  Risks flagged: 4\n","\n","üîÑ Step 6: Workflow Risk Assessment\n","‚úì Risk assessment complete\n","\n","‚úÖ Case finalized: completed\n","üìÅ Deliverables saved: /content/run_20260115_155535_110b2989/deliverables/case_02_concentrated_stock\n","\n","============================================================\n","CASE: case_03_alternatives\n","============================================================\n","\n","üîÑ Step 1: Intake & Structuring\n","‚úì Intake complete\n","  Facts: 6\n","  Assumptions: 5\n","  Open questions: 5\n","\n","üîÑ Step 2: IPS Shell Drafting\n","‚úì IPS shell drafted\n","\n","üîÑ Step 3: Disclosure Checklist\n","‚úì Disclosure checklist created\n","\n","üîÑ Step 4: Suitability Reasoning Scaffold\n","\n","‚ùå Error in case_03_alternatives: Missing keys: ['open_questions']\n","\n","============================================================\n","CASE: case_04_practice_mgmt\n","============================================================\n","\n","üîÑ Step 1: Intake & Structuring\n","‚úì Intake complete\n","  Facts: 7\n","  Assumptions: 5\n","  Open questions: 5\n","\n","üîÑ Step 2: IPS Shell Drafting\n","‚úì IPS shell drafted\n","\n","üîÑ Step 3: Disclosure Checklist\n","‚úì Disclosure checklist created\n","\n","üîÑ Step 4: Suitability Reasoning Scaffold\n","‚úì Reasoning scaffold drafted\n","\n","üîÑ Step 5: QC Review\n","‚úì QC review complete\n","  Risks flagged: 4\n","\n","üîÑ Step 6: Workflow Risk Assessment\n","‚úì Risk assessment complete\n","\n","‚úÖ Case finalized: completed\n","üìÅ Deliverables saved: /content/run_20260115_155535_110b2989/deliverables/case_04_practice_mgmt\n","\n","============================================================\n","ALL CASES COMPLETE\n","============================================================\n","‚úÖ case_01_retirement: completed\n","‚úÖ case_02_concentrated_stock: completed\n","‚ö†Ô∏è case_03_alternatives: failed\n","‚úÖ case_04_practice_mgmt: completed\n"]}]},{"cell_type":"markdown","source":["##10.ARTIFACT BUNDLE"],"metadata":{"id":"deALRI7DNc11"}},{"cell_type":"markdown","source":["###10.1.OVERVIEW"],"metadata":{"id":"hspK-tF8Nd9D"}},{"cell_type":"markdown","source":["Cell 10 Output Explanation:\n","\n","Cell 10 packages everything generated during the workflow into a comprehensive, downloadable supervision file. Think of this as creating a complete case binder that a compliance officer or auditor could review to understand exactly what happened during the AI-assisted advisory process.\n","\n","The cell first generates an extensive README document that serves as the cover memo and user guide for the entire package. This README is approximately 5000 words and includes detailed sections explaining what the package contains, what the AI agents did and did not do, governance principles applied, supervision checklists, usage instructions, and technical details about how the system works. The README emphasizes repeatedly that the outputs are not investment advice and require qualified advisor review.\n","\n","Next, the cell creates a package summary JSON file that provides programmatic access to key information. This machine-readable summary includes the run identifier, timestamp, complete manifest, status of each case (completed or failed), file paths for all artifacts, and any error messages. This allows automated tools to process the package without parsing the human-readable README.\n","\n","The cell then gathers statistics from the execution: total number of risks logged, how many were high-severity, total audit log entries, and case completion rates. These metrics provide quick insight into workflow quality and any problems that occurred.\n","\n","All files are then bundled into a single ZIP archive. The compression process recursively walks through the entire run directory, adding every file while preserving the folder structure. The resulting ZIP contains the manifest, README, package summary, immutable logs, risk register, and separate subfolders for each case with their artifacts, registers, and checkpoint histories.\n","\n","The output displays a comprehensive final summary showing execution statistics, package contents inventory, governance artifacts included, demonstrations completed, and reminders about the advisory review requirement. You'll see exact numbers for completed versus failed cases, total log entries, and risks detected.\n","\n","Finally, the cell provides clear download instructions with two options: manually downloading from Colab's file browser, or running a code snippet to trigger automatic download. The closing messages emphasize next steps for advisors reviewing the package and reinforce the educational value of the governance-first approach demonstrated throughout the notebook."],"metadata":{"id":"QktoO36gNwPN"}},{"cell_type":"markdown","source":["###10.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"-qPlPvQYNhIv"}},{"cell_type":"code","source":["# Cell 10\n","# Goal: Create README and bundle all artifacts into downloadable zip\n","# Output: Zip file ready for download with complete supervision package\n","\n","# Create comprehensive README\n","readme_content = f\"\"\"# Chapter 3 - Level 3 Agentic Advisory Workflow Run\n","## Run ID: {RUN_ID}\n","## Generated: {datetime.now().isoformat()}\n","\n","---\n","\n","### ‚ö†Ô∏è DISCLAIMER\n","NOT INVESTMENT, TAX, OR LEGAL ADVICE.\n","This package contains draft planning and communication assistance only.\n","Qualified advisor review and supervision required.\n","\n","---\n","\n","### GOVERNANCE SUMMARY\n","\n","**Model:** claude-sonnet-4-5-20250929 (Anthropic)\n","**Config Hash:** {MANIFEST['config_hash']}\n","**Temperature:** 0.2\n","**Max Tokens:** 4096\n","\n","---\n","\n","### CONTENTS\n","\n","üìÅ **Root Files:**\n","- `run_manifest.json` - Run metadata, model config, environment fingerprint\n","- `README.md` - This file\n","\n","üìÅ **logs/**\n","- `prompts_log.jsonl` - Immutable hash-chained audit trail (each entry links to previous)\n","- `risk_log.json` - Risk register with all flagged items across workflow\n","\n","üìÅ **deliverables/** (one subfolder per case)\n","Each case folder contains:\n","- `artifacts.json` - All agent outputs (intake, IPS, disclosure, suitability, QC, risk assessment)\n","- `registers.json` - Assumption register, open items register, not-verified register\n","- `checkpoints.json` - Human approval gate history with timestamps\n","\n","---\n","\n","### CASE EXECUTION SUMMARY\n","\n","\"\"\"\n","\n","# Add case results\n","for cid, result in results.items():\n","    status = result.get('status', 'unknown')\n","    status_icon = \"‚úÖ\" if status == \"completed\" else \"‚ö†Ô∏è\" if status == \"failed\" else \"üîÑ\"\n","    case_name = cid.replace('case_', '').replace('_', ' ').title()\n","    readme_content += f\"**{status_icon} {case_name}**\\n\"\n","    readme_content += f\"- Status: {status}\\n\"\n","    if status == \"completed\":\n","        readme_content += f\"- Artifacts: {result.get('artifacts_path', 'N/A')}\\n\"\n","        readme_content += f\"- Registers: {result.get('registers_path', 'N/A')}\\n\"\n","        readme_content += f\"- Checkpoints: {result.get('checkpoints_path', 'N/A')}\\n\"\n","    elif status == \"failed\":\n","        readme_content += f\"- Error: {result.get('error', 'Unknown error')}\\n\"\n","    readme_content += \"\\n\"\n","\n","readme_content += \"\"\"---\n","\n","### GOVERNANCE ARTIFACTS DETAIL\n","\n","‚úÖ **Traceability**\n","- `run_manifest.json`: Complete run configuration and environment snapshot\n","- `prompts_log.jsonl`: Hash-chained immutable log prevents tampering\n","  - Each entry contains: step_id, agent_name, prompt_hash, response_hash, prev_hash\n","  - Chain integrity can be verified by checking prev_hash linkage\n","\n","‚úÖ **Risk Register**\n","- `risk_log.json`: All risks detected during workflow execution\n","- Risk types tracked:\n","  - confidentiality (PII handling)\n","  - hallucination (invented facts/authority)\n","  - missing_facts (incomplete information)\n","  - suitability (suitability determination language)\n","  - regbi (Reg BI compliance language)\n","  - conflicts (conflict of interest gaps)\n","  - liquidity (liquidity mismatch)\n","  - prompt_injection (security issues)\n","  - overreach (scope boundary violations)\n","  - workflow_integrity_gap (missing checkpoints, structural issues)\n","  - hinge_fact_unresolved_block (critical facts blocking workflow)\n","\n","‚úÖ **Assumption Registers**\n","- Per-case tracking of all assumptions made during workflow\n","- Hinge facts flagged (critical assumptions that block downstream steps if unresolved)\n","- Resolution status tracked for supervision review\n","\n","‚úÖ **Checkpoint History**\n","- All human-in-the-loop approval gates logged with timestamps\n","- Auto-approval status recorded (in production, would require manual approval)\n","- Checkpoint names indicate workflow stage\n","\n","‚úÖ **Immutable Audit Trail**\n","- Hash-chained log prevents post-hoc modification\n","- Redacted prompts/responses protect confidentiality while maintaining auditability\n","- Suitable for supervision files and regulatory examination\n","\n","---\n","\n","### LEVEL 3 ARCHITECTURE OVERVIEW\n","\n","**Agentic Workflow Pattern:**\n","This notebook demonstrates a multi-agent orchestration pattern where:\n","1. A central Orchestrator manages workflow state and progression\n","2. Specialized agents handle discrete workflow steps\n","3. Explicit human checkpoints gate workflow advancement\n","4. Shared state tracks assumptions, open items, and verification needs\n","5. Immutable logs ensure auditability\n","\n","**Agents:**\n","- **OrchestratorAgent** - Workflow state machine, enforces checkpoint gates\n","- **IntakeAgent** - Structures client scenarios, extracts facts/assumptions\n","- **IPSDraftAgent** - Generates Investment Policy Statement shells (process only, no allocations)\n","- **DisclosureAgent** - Creates disclosure checklists (conflicts, fees, risks, limitations)\n","- **SuitabilityReasoningAgent** - Drafts reasoning scaffolds (questions, NOT conclusions)\n","- **QCReviewerAgent** - Reviews artifacts for gaps, inconsistencies, missing items\n","- **RiskAssessorAgent** - Evaluates workflow-level risks and integrity\n","- **Logger** - Maintains immutable hash-chained audit trail\n","\n","**Shared State Components:**\n","- Assumption register (with hinge fact flags)\n","- Open items register (unresolved questions)\n","- Not-verified register (items requiring external verification)\n","- Checkpoint history (human approval gates)\n","\n","**Checkpoint Mechanism:**\n","Three standard checkpoints per workflow:\n","1. Post-intake review (verify facts, assumptions, hinge facts)\n","2. Post-drafts review (verify IPS, disclosures, suitability scaffolds)\n","3. Final approval gate (authorize deliverable package)\n","\n","**Hinge Fact Enforcement:**\n","- Critical assumptions flagged as \"hinge facts\"\n","- Unresolved hinge facts BLOCK downstream drafting steps\n","- Ensures workflow doesn't proceed on unvalidated critical assumptions\n","- Logged in risk register if blocking occurs\n","\n","---\n","\n","### SUPERVISION FILE CHECKLIST\n","\n","**For each case, advisor must review:**\n","\n","‚òê **1. Intake Artifacts**\n","- Are all stated facts accurate and complete?\n","- Are assumptions reasonable and documented?\n","- Are hinge facts identified and resolved?\n","- Are open questions addressed or escalated?\n","\n","‚òê **2. Draft Outputs** (IPS, Disclosures, Suitability)\n","- Do drafts align with firm standards and templates?\n","- Are all material risks disclosed?\n","- Is reasoning scaffold complete without making determinations?\n","- Does content avoid recommendations and allocations?\n","\n","‚òê **3. QC Notes**\n","- Are identified gaps addressed?\n","- Are inconsistencies resolved?\n","- Are missing items documented in follow-up plan?\n","\n","‚òê **4. Risk Register**\n","- Are all flagged risks reviewed?\n","- Are high-severity risks mitigated or documented?\n","- Is workflow integrity maintained (no missing checkpoints)?\n","\n","‚òê **5. Checkpoint History**\n","- Were all approval gates completed?\n","- Is approval documentation adequate for supervision file?\n","- Are checkpoint timestamps consistent with workflow progression?\n","\n","‚òê **6. Registers Review**\n","- Assumption register: Are all assumptions validated or flagged for follow-up?\n","- Open items register: Are critical items addressed before implementation?\n","- Not-verified register: Are regulatory/authority claims verified externally?\n","\n","---\n","\n","### WHAT AGENTS DID (SCOPE)\n","\n","‚úÖ **Structured intake workflows**\n","- Extracted facts from scenarios\n","- Identified assumptions and alternatives\n","- Flagged open questions and unknowns\n","\n","‚úÖ **Drafted IPS shells**\n","- Created process/governance frameworks\n","- Avoided allocations and specific targets\n","- Focused on roles, responsibilities, review schedules\n","\n","‚úÖ **Generated disclosure checklists**\n","- Identified disclosure topics (conflicts, compensation, risks, limitations)\n","- Created advisor review checklists\n","- Avoided compliance assertions\n","\n","‚úÖ **Created suitability reasoning scaffolds**\n","- Structured questions advisor must answer\n","- Identified alternatives for comparison\n","- Flagged risks and conflicts to address\n","\n","‚úÖ **Flagged risks and gaps**\n","- QC review identified missing information\n","- Risk assessment evaluated workflow integrity\n","- Both flagged items for advisor follow-up\n","\n","‚úÖ **Maintained audit trail**\n","- Immutable hash-chained logs\n","- Risk register with all detections\n","- Checkpoint history for supervision\n","\n","---\n","\n","### WHAT AGENTS DID NOT DO (BOUNDARIES)\n","\n","‚ùå **Did NOT recommend specific investments**\n","- No securities, tickers, funds, or products named\n","- No allocations or portfolio weightings specified\n","- No \"buy\" or \"sell\" guidance provided\n","\n","‚ùå **Did NOT determine suitability or best interest**\n","- Only drafted reasoning scaffolds and questions\n","- Did not conclude \"suitable\" or \"unsuitable\"\n","- Did not assert Reg BI or fiduciary compliance\n","\n","‚ùå **Did NOT assert compliance**\n","- All regulatory references marked \"Not verified\"\n","- No claims of meeting regulatory standards\n","- No compliance determinations made\n","\n","‚ùå **Did NOT execute transactions**\n","- No trades, transfers, or portfolio actions\n","- No account changes or implementations\n","\n","‚ùå **Did NOT replace advisor judgment**\n","- All outputs require qualified advisor review\n","- Checkpoints enforce human-in-the-loop\n","- Supervision and final approval required\n","\n","---\n","\n","### USAGE NOTES FOR ADVISORS\n","\n","**This package is designed for:**\n","- Supervision files documenting AI-assisted workflow\n","- Compliance review of agentic process controls\n","- Audit trail for regulatory examination\n","- Training on governance-first AI implementation\n","\n","**How to use deliverables:**\n","1. Review README (this file) for package overview\n","2. Check run_manifest.json for configuration details\n","3. Review risk_log.json for any high-severity items\n","4. For each case:\n","   - Read artifacts.json to review all agent outputs\n","   - Check registers.json for assumptions/open items needing attention\n","   - Verify checkpoints.json shows proper approval gates\n","5. Use supervision checklist above for systematic review\n","6. Document advisor review, decisions, and follow-up in firm systems\n","\n","**Best practices:**\n","- Never use AI outputs without qualified advisor review\n","- Verify all regulatory/authority claims independently\n","- Resolve all hinge facts before implementation\n","- Document deviations from AI suggestions with rationale\n","- Maintain human decision-making primacy\n","- Keep AI assistance documented for supervision files\n","\n","---\n","\n","### GOVERNANCE-FIRST PRINCIPLE\n","\n","**Capability ‚Üë ‚áí Risk ‚Üë ‚áí Controls ‚Üë**\n","\n","As AI capabilities increase (Level 1 ‚Üí Level 2 ‚Üí Level 3 ‚Üí beyond):\n","- Risk exposure increases (scope, autonomy, impact)\n","- Controls must increase proportionally (logging, checkpoints, boundaries)\n","- Supervision requirements intensify (review, approval, documentation)\n","\n","Level 3 (Agents) introduces:\n","- Multi-step workflows (more surface area for errors)\n","- Agent orchestration (coordination complexity)\n","- Longer execution chains (compounding risk)\n","\n","Required controls for Level 3:\n","- Explicit human checkpoints (workflow gates)\n","- Immutable audit trails (tamper-evident logs)\n","- Hinge fact enforcement (blocking logic)\n","- Structured output validation (schema enforcement)\n","- Risk detection patterns (real-time monitoring)\n","- Scope boundaries (hard limits on agent authority)\n","\n","---\n","\n","### CONTACT & ATTRIBUTION\n","\n","**Author:** Alejandro Reynoso\n","**Title:** Chief Scientist, DEFI CAPITAL RESEARCH\n","**Affiliation:** External Lecturer, Judge Business School Cambridge\n","\n","**Model:** claude-sonnet-4-5-20250929 (Anthropic)\n","**Chapter:** Chapter 3 - Level 3 (Agents): Multi-Step Advisory Workflows\n","**Notebook Version:** 1.0\n","**Date:** {datetime.now().strftime('%B %d, %Y')}\n","\n","---\n","\n","### TECHNICAL NOTES\n","\n","**Token Management:**\n","- Max tokens: 4096 per agent call\n","- Response length limits enforced in prompts\n","- Retry logic handles truncation issues\n","\n","**JSON Validation:**\n","- Strict schema enforcement on all LLM outputs\n","- Required keys validated pre-acceptance\n","- Non-JSON responses trigger retries and risk logging\n","\n","**Hash Chain Integrity:**\n","- prompts_log.jsonl uses SHA-256 hash chaining\n","- Each entry's prev_hash links to prior entry's response_hash\n","- Genesis block initializes chain with null hashes\n","- Chain can be verified programmatically for tampering detection\n","\n","**Confidentiality:**\n","- All prompts/responses redacted before logging\n","- PII patterns (SSN, email, phone, account numbers) removed\n","- Case data sanitized with warnings against real client data\n","\n","---\n","\n","### VERSION HISTORY\n","\n","**v1.0** - Initial release\n","- 10-cell notebook structure\n","- 4 mini-case demonstrations\n","- Full governance artifact generation\n","- Immutable logging and risk register\n","- Checkpoint enforcement\n","- Hinge fact blocking logic\n","\n","---\n","\n","**END OF README**\n","\n","For questions or feedback on this governance-first agentic workflow framework, please contact the author.\n","\"\"\"\n","\n","# Write README\n","readme_path = RUN_DIR / \"README.md\"\n","with open(readme_path, \"w\") as f:\n","    f.write(readme_content)\n","\n","print(f\"‚úì README created: {readme_path}\")\n","print(f\"  Length: {len(readme_content)} characters\")\n","\n","# Create package summary JSON for programmatic access\n","package_summary = {\n","    \"run_id\": RUN_ID,\n","    \"timestamp\": datetime.now().isoformat(),\n","    \"manifest\": MANIFEST,\n","    \"cases\": {\n","        case_id: {\n","            \"status\": result.get(\"status\", \"unknown\"),\n","            \"artifacts_path\": result.get(\"artifacts_path\"),\n","            \"registers_path\": result.get(\"registers_path\"),\n","            \"checkpoints_path\": result.get(\"checkpoints_path\"),\n","            \"error\": result.get(\"error\")\n","        }\n","        for case_id, result in results.items()\n","    },\n","    \"files\": {\n","        \"readme\": str(readme_path),\n","        \"manifest\": str(RUN_DIR / \"run_manifest.json\"),\n","        \"prompts_log\": str(LOGS_DIR / \"prompts_log.jsonl\"),\n","        \"risk_log\": str(LOGS_DIR / \"risk_log.json\")\n","    }\n","}\n","\n","summary_path = RUN_DIR / \"package_summary.json\"\n","with open(summary_path, \"w\") as f:\n","    json.dump(package_summary, f, indent=2)\n","\n","print(f\"‚úì Package summary created: {summary_path}\")\n","\n","# Count total risks logged\n","with open(LOGS_DIR / \"risk_log.json\", \"r\") as f:\n","    risk_log = json.load(f)\n","    total_risks = len(risk_log.get(\"risks\", []))\n","    high_severity_risks = len([r for r in risk_log.get(\"risks\", []) if r.get(\"severity\") == \"high\"])\n","\n","print(f\"‚úì Risk register: {total_risks} total risks, {high_severity_risks} high-severity\")\n","\n","# Count log entries\n","with open(LOGS_DIR / \"prompts_log.jsonl\", \"r\") as f:\n","    log_lines = f.readlines()\n","    log_entries = len(log_lines)\n","\n","print(f\"‚úì Immutable log: {log_entries} entries (hash-chained)\")\n","\n","# Create zip bundle\n","zip_path = Path(f\"/content/{RUN_ID}.zip\")\n","print(f\"\\nüì¶ Creating zip bundle...\")\n","\n","with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n","    for file_path in RUN_DIR.rglob(\"*\"):\n","        if file_path.is_file():\n","            arcname = file_path.relative_to(RUN_DIR.parent)\n","            zipf.write(file_path, arcname)\n","\n","zip_size_mb = zip_path.stat().st_size / (1024 * 1024)\n","print(f\"‚úì Zip bundle created: {zip_path}\")\n","print(f\"‚úì Bundle size: {zip_size_mb:.2f} MB\")\n","\n","# Generate final statistics\n","completed_cases = sum(1 for r in results.values() if r.get(\"status\") == \"completed\")\n","failed_cases = sum(1 for r in results.values() if r.get(\"status\") == \"failed\")\n","total_cases = len(results)\n","\n","# Display final summary\n","print(f\"\\n{'='*70}\")\n","print(f\"CHAPTER 3 - LEVEL 3 AGENTIC WORKFLOWS COMPLETE\")\n","print(f\"{'='*70}\")\n","print(f\"\\nüìä EXECUTION SUMMARY:\")\n","print(f\"   Run ID: {RUN_ID}\")\n","print(f\"   Total Cases: {total_cases}\")\n","print(f\"   ‚úÖ Completed: {completed_cases}\")\n","print(f\"   ‚ö†Ô∏è  Failed: {failed_cases}\")\n","print(f\"   üìù Log Entries: {log_entries}\")\n","print(f\"   üö® Risks Logged: {total_risks} ({high_severity_risks} high-severity)\")\n","\n","print(f\"\\nüìÅ DELIVERABLES PACKAGE:\")\n","print(f\"   üì¶ Zip file: {zip_path.name}\")\n","print(f\"   üíæ Size: {zip_size_mb:.2f} MB\")\n","print(f\"   üìÑ Contents:\")\n","print(f\"      - run_manifest.json (configuration)\")\n","print(f\"      - README.md (comprehensive documentation)\")\n","print(f\"      - package_summary.json (programmatic summary)\")\n","print(f\"      - logs/prompts_log.jsonl (immutable audit trail)\")\n","print(f\"      - logs/risk_log.json (risk register)\")\n","print(f\"      - deliverables/{total_cases} case folders (artifacts + registers + checkpoints)\")\n","\n","print(f\"\\n‚úÖ GOVERNANCE ARTIFACTS INCLUDED:\")\n","print(f\"   ‚úì Traceability: run_manifest.json + immutable hash-chained log\")\n","print(f\"   ‚úì Risk Register: All workflow risks documented\")\n","print(f\"   ‚úì Assumption Registers: Per-case tracking with hinge fact flags\")\n","print(f\"   ‚úì Checkpoint History: Human-in-the-loop approval gates logged\")\n","print(f\"   ‚úì Audit Trail: Tamper-evident, suitable for supervision files\")\n","\n","print(f\"\\nüéØ LEVEL 3 DEMONSTRATIONS:\")\n","print(f\"   ‚úì Multi-step agentic workflow orchestration\")\n","print(f\"   ‚úì Explicit human checkpoints at workflow gates\")\n","print(f\"   ‚úì Fact vs assumption separation with hinge fact blocking\")\n","print(f\"   ‚úì Suitability/Reg BI reasoning scaffolds (not determinations)\")\n","print(f\"   ‚úì Immutable logs and versioned deliverables\")\n","print(f\"   ‚úì Scope boundaries enforced (no recommendations/allocations)\")\n","\n","print(f\"\\n‚ö†Ô∏è  REMINDER:\")\n","print(f\"   NOT INVESTMENT, TAX, OR LEGAL ADVICE\")\n","print(f\"   All outputs require qualified advisor review and supervision\")\n","print(f\"   This package demonstrates governance-first agentic architecture\")\n","\n","print(f\"\\n{'='*70}\")\n","print(f\"READY FOR DOWNLOAD\")\n","print(f\"{'='*70}\")\n","\n","# Provide download instructions\n","print(f\"\\nüì• TO DOWNLOAD THE SUPERVISION PACKAGE:\")\n","print(f\"\\n   Option 1 - From Files Panel:\")\n","print(f\"   1. Click the üìÅ folder icon in left sidebar\")\n","print(f\"   2. Navigate to: {zip_path.name}\")\n","print(f\"   3. Click ‚ãÆ menu ‚Üí Download\")\n","\n","print(f\"\\n   Option 2 - Run this code:\")\n","print(f\"   ```python\")\n","print(f\"   from google.colab import files\")\n","print(f\"   files.download('{zip_path}')\")\n","print(f\"   ```\")\n","\n","print(f\"\\nüí° NEXT STEPS:\")\n","print(f\"   1. Download the zip file\")\n","print(f\"   2. Extract and review README.md\")\n","print(f\"   3. Use supervision checklist for systematic review\")\n","print(f\"   4. Examine risk_log.json for high-severity items\")\n","print(f\"   5. Review each case's artifacts, registers, and checkpoints\")\n","\n","print(f\"\\nüéì EDUCATIONAL VALUE:\")\n","print(f\"   This notebook demonstrates:\")\n","print(f\"   - Governance-first principle: Capability ‚Üë ‚áí Risk ‚Üë ‚áí Controls ‚Üë\")\n","print(f\"   - Production-ready agentic architecture for financial advisory\")\n","print(f\"   - Appropriate scope boundaries for Level 3 AI workflows\")\n","print(f\"   - Audit trail and documentation for regulatory supervision\")\n","\n","print(f\"\\n{'='*70}\")\n","print(f\"Chapter 3 notebook execution complete. Package ready for supervision file.\")\n","print(f\"{'='*70}\\n\")\n","\n","# Auto-download helper (commented out by default - user can uncomment to auto-download)\n","# Uncomment the lines below to automatically trigger download\n","# from google.colab import files\n","# files.download(str(zip_path))\n","# print(f\"‚¨áÔ∏è  Download started automatically\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cxy-yUW9cCQm","executionInfo":{"status":"ok","timestamp":1768493713853,"user_tz":360,"elapsed":88,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"f3539d53-1ead-40a2-9337-712ca61cbb1b"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì README created: /content/run_20260115_155535_110b2989/README.md\n","  Length: 12401 characters\n","‚úì Package summary created: /content/run_20260115_155535_110b2989/package_summary.json\n","‚úì Risk register: 2 total risks, 2 high-severity\n","‚úì Immutable log: 22 entries (hash-chained)\n","\n","üì¶ Creating zip bundle...\n","‚úì Zip bundle created: /content/run_20260115_155535_110b2989.zip\n","‚úì Bundle size: 0.03 MB\n","\n","======================================================================\n","CHAPTER 3 - LEVEL 3 AGENTIC WORKFLOWS COMPLETE\n","======================================================================\n","\n","üìä EXECUTION SUMMARY:\n","   Run ID: run_20260115_155535_110b2989\n","   Total Cases: 4\n","   ‚úÖ Completed: 3\n","   ‚ö†Ô∏è  Failed: 1\n","   üìù Log Entries: 22\n","   üö® Risks Logged: 2 (2 high-severity)\n","\n","üìÅ DELIVERABLES PACKAGE:\n","   üì¶ Zip file: run_20260115_155535_110b2989.zip\n","   üíæ Size: 0.03 MB\n","   üìÑ Contents:\n","      - run_manifest.json (configuration)\n","      - README.md (comprehensive documentation)\n","      - package_summary.json (programmatic summary)\n","      - logs/prompts_log.jsonl (immutable audit trail)\n","      - logs/risk_log.json (risk register)\n","      - deliverables/4 case folders (artifacts + registers + checkpoints)\n","\n","‚úÖ GOVERNANCE ARTIFACTS INCLUDED:\n","   ‚úì Traceability: run_manifest.json + immutable hash-chained log\n","   ‚úì Risk Register: All workflow risks documented\n","   ‚úì Assumption Registers: Per-case tracking with hinge fact flags\n","   ‚úì Checkpoint History: Human-in-the-loop approval gates logged\n","   ‚úì Audit Trail: Tamper-evident, suitable for supervision files\n","\n","üéØ LEVEL 3 DEMONSTRATIONS:\n","   ‚úì Multi-step agentic workflow orchestration\n","   ‚úì Explicit human checkpoints at workflow gates\n","   ‚úì Fact vs assumption separation with hinge fact blocking\n","   ‚úì Suitability/Reg BI reasoning scaffolds (not determinations)\n","   ‚úì Immutable logs and versioned deliverables\n","   ‚úì Scope boundaries enforced (no recommendations/allocations)\n","\n","‚ö†Ô∏è  REMINDER:\n","   NOT INVESTMENT, TAX, OR LEGAL ADVICE\n","   All outputs require qualified advisor review and supervision\n","   This package demonstrates governance-first agentic architecture\n","\n","======================================================================\n","READY FOR DOWNLOAD\n","======================================================================\n","\n","üì• TO DOWNLOAD THE SUPERVISION PACKAGE:\n","\n","   Option 1 - From Files Panel:\n","   1. Click the üìÅ folder icon in left sidebar\n","   2. Navigate to: run_20260115_155535_110b2989.zip\n","   3. Click ‚ãÆ menu ‚Üí Download\n","\n","   Option 2 - Run this code:\n","   ```python\n","   from google.colab import files\n","   files.download('/content/run_20260115_155535_110b2989.zip')\n","   ```\n","\n","üí° NEXT STEPS:\n","   1. Download the zip file\n","   2. Extract and review README.md\n","   3. Use supervision checklist for systematic review\n","   4. Examine risk_log.json for high-severity items\n","   5. Review each case's artifacts, registers, and checkpoints\n","\n","üéì EDUCATIONAL VALUE:\n","   This notebook demonstrates:\n","   - Governance-first principle: Capability ‚Üë ‚áí Risk ‚Üë ‚áí Controls ‚Üë\n","   - Production-ready agentic architecture for financial advisory\n","   - Appropriate scope boundaries for Level 3 AI workflows\n","   - Audit trail and documentation for regulatory supervision\n","\n","======================================================================\n","Chapter 3 notebook execution complete. Package ready for supervision file.\n","======================================================================\n","\n"]}]},{"cell_type":"markdown","source":["##11.CONCLUSIONS"],"metadata":{"id":"7X2_AKt3NkAR"}},{"cell_type":"markdown","source":["\n","\n","**Overview of the Advisory Workflow Pipeline**\n","\n","This notebook demonstrates a sophisticated end-to-end pipeline that transforms unstructured client scenarios into governed, audit-ready advisory workflow artifacts. The pipeline represents a Level 3 agentic system where multiple AI agents collaborate through structured data exchanges, human checkpoints, and immutable logging to assist financial advisors while maintaining strict compliance boundaries. Understanding this pipeline reveals how modern AI can augment professional advisory work without replacing human judgment or violating regulatory requirements.\n","\n","**Stage 1: User Input - The Starting Point**\n","\n","The pipeline begins when a user provides an unstructured client scenario as plain text. This input might be a paragraph or several paragraphs describing a client situation, such as retirement planning needs, concentrated stock positions, alternative investment interests, or practice management challenges. The scenario typically includes facts like client age, asset values, goals, risk tolerance, and specific questions the advisor needs to address.\n","\n","This raw input is intentionally unstructured because that mirrors real-world advisory practice. Advisors receive information through conversations, emails, notes from meetings, or intake forms that vary in format and completeness. The AI system must be able to process this natural, unorganized information and transform it into something actionable.\n","\n","In Cell 9, four such scenarios are defined as simple Python strings. For example, Case 1 presents a retirement scenario with biographical details, asset information, income needs, pension details, Social Security considerations, risk concerns, health status, and planning questions all mixed together in narrative form. This messy, real-world format is what the pipeline must handle.\n","\n","**Stage 2: Intake Agent - Initial Structuring**\n","\n","The first transformation occurs when the OrchestratorAgent hands the raw scenario to the IntakeAgent. The orchestrator calls the intake agent's process method, passing the case identifier and the raw scenario text. The IntakeAgent then constructs a prompt for the Claude AI model.\n","\n","This prompt has two critical components. The system prompt defines the agent's role, boundaries, and output requirements. It states that the agent extracts facts, identifies assumptions, flags unknowns, never recommends investments, and must respond with valid JSON only. The user prompt contains the actual scenario text along with explicit instructions about what to extract and how to structure the response.\n","\n","Crucially, the prompt specifies the exact JSON schema required. The agent must return ten specific fields: task description, facts_provided list, assumptions list, alternatives list, open_questions list, analysis text, risks array, draft_output text, verification_status field, and questions_to_verify list. The prompt also specifies length constraints for each field to prevent token limit problems.\n","\n","**Stage 3: LLM Wrapper - Quality Control Gateway**\n","\n","Before the prompt reaches the Claude AI model, it passes through the StrictJSONLLMWrapper, which acts as a quality control gateway. The wrapper enhances the system prompt by injecting additional requirements about JSON formatting, length limits, and the mandatory disclaimer that must appear in all outputs.\n","\n","The wrapper then makes the API call to Anthropic's service using the configured model (claude-sonnet-4-5-20250929) with specified parameters: 4096 maximum tokens, 0.2 temperature for consistency, and the enhanced system and user prompts. The AI model processes these instructions and generates a response.\n","\n","When the response returns, the wrapper performs multiple validation steps before accepting it. First, it strips any markdown formatting that might have been included. Second, it attempts to parse the response as JSON. If parsing fails, the wrapper checks whether truncation occurred and can retry with more concise prompts. Third, it validates that all ten required fields are present in the parsed JSON. Fourth, it ensures array fields contain at least placeholder values if empty. Fifth, it runs pattern detection looking for problematic content like implied recommendations, suitability determinations, or unverified regulatory citations.\n","\n","If any validation fails, the wrapper logs the failure to the risk register and either retries or raises an error. If all validations pass, the wrapper logs the redacted prompt and response to the immutable audit trail using hash chaining, then returns the validated JSON structure to the calling agent.\n","\n","**Stage 4: JSON Processing - Data Registration**\n","\n","The IntakeAgent receives the validated JSON structure from the wrapper and returns it to the OrchestratorAgent. The orchestrator now processes this structured data by registering it into the SharedState system.\n","\n","The orchestrator iterates through the assumptions list, examining each assumption's text for keywords like \"critical\" or \"must\" that indicate it might be a hinge fact. Hinge facts are assumptions so important that if they remain unresolved, the workflow should not proceed to drafting recommendations. Each assumption gets registered with its hinge fact status.\n","\n","Similarly, the orchestrator extracts all items from the open_questions list and registers them as open items requiring follow-up. Items from the questions_to_verify list get registered into the not-verified register, flagging claims that need external validation.\n","\n","The complete intake artifact, with all ten JSON fields, gets stored in the case's artifacts collection within the shared state. This creates a permanent record of the intake step that later agents can reference.\n","\n","**Stage 5: Checkpoint Enforcement - Human Review Gates**\n","\n","After intake completes and data registration finishes, the orchestrator reaches Checkpoint 1. The checkpoint mechanism logs this moment with a timestamp, checkpoint name, case identifier, and approval status. In this demonstration, checkpoints auto-approve for smooth execution, but in production environments, these would pause the workflow requiring actual human review before proceeding.\n","\n","The orchestrator then calls the check_hinge_facts method on the shared state. This method examines the assumption register looking for any assumptions marked as hinge facts that remain unresolved. If unresolved hinge facts exist, the method logs a high-severity risk to the risk register and returns false, which causes the orchestrator to stop the workflow and finalize the case with a \"blocked by hinge facts\" status.\n","\n","If all hinge facts are resolved or no hinge facts exist, the workflow continues to the drafting agents.\n","\n","**Stage 6: Sequential Agent Processing - Building the Package**\n","\n","The orchestrator now executes agents sequentially, with each agent building on previous agents' work. The IPSDraftAgent receives the intake results as input. Rather than passing the raw scenario again, it receives the structured JSON from intake containing extracted facts and identified assumptions. The IPS agent uses these structured inputs to generate an Investment Policy Statement shell.\n","\n","The agent constructs its own prompt that references facts from the intake JSON. This prompt explicitly instructs the AI to create IPS sections (Purpose, Roles, Process, Review Schedule) without specifying allocations or targets. The prompt again requires the ten-field JSON structure with length limits.\n","\n","The wrapper processes this prompt through the same quality control pipeline: enhancement, API call, validation, pattern detection, logging, and return. The validated IPS JSON gets stored in the case artifacts.\n","\n","The DisclosureAgent follows the same pattern, receiving intake results and generating a disclosure checklist JSON. The SuitabilityReasoningAgent similarly processes intake data to create a structured reasoning scaffold with questions the advisor must answer.\n","\n","After these three drafting agents complete, Checkpoint 2 pauses for review of all draft materials before proceeding to quality control.\n","\n","**Stage 7: Quality Control and Risk Assessment**\n","\n","The QCReviewerAgent receives all accumulated artifacts as input. Rather than the raw scenario or intake results, it examines the complete collection: intake JSON, IPS JSON, disclosure JSON, and suitability JSON. The QC agent looks for gaps where information is missing, inconsistencies where different agents made conflicting assumptions, and risks that were not adequately addressed in earlier steps.\n","\n","The QC review outputs its findings in the same ten-field JSON structure. The risks array typically contains multiple entries identifying specific problems like \"missing retirement expense breakdown\" or \"concentration risk not addressed in disclosures.\" The draft_output field provides a summary of findings for the advisor to review.\n","\n","The RiskAssessorAgent then examines the entire workflow state, not just the artifacts. It receives the SharedState object giving it access to the assumption register, open items register, not-verified register, and checkpoint history. This agent evaluates whether the workflow itself was executed properly: Were all checkpoints completed? Are there too many unresolved assumptions? Did any agent skip required verification steps?\n","\n","The risk assessment JSON identifies workflow integrity issues, which are distinct from content issues. A workflow integrity problem might be \"multiple regulatory claims in disclosures but none flagged for verification\" or \"hinge fact identified but resolution not documented.\"\n","\n","After risk assessment completes, the Final Checkpoint requires approval before the package can be marked as ready for delivery.\n","\n","**Stage 8: Artifact Finalization - Creating Supervision Files**\n","\n","When the workflow completes (either successfully or by early termination at a checkpoint), the orchestrator's finalize method executes. This creates a subfolder within the deliverables directory named after the case identifier. Inside this folder, three JSON files are written.\n","\n","The artifacts.json file contains the complete output from all six agents: intake, IPS, disclosure, suitability, QC, and risk assessment. Each agent's ten-field JSON structure is preserved exactly as validated. This file provides the substantive content of the workflow - the actual drafts and analysis.\n","\n","The registers.json file contains three arrays extracted from the shared state: all assumptions with their hinge fact flags and resolution status, all open items identified throughout the workflow, and all not-verified claims that need external validation. This file helps supervisors understand what remains uncertain or unvalidated.\n","\n","The checkpoints.json file contains the complete history of checkpoint events: when each checkpoint occurred, whether it was auto-approved or manually approved, and which case it applied to. This provides audit evidence that human review gates were implemented.\n","\n","**Stage 9: Immutable Logging - Creating the Audit Trail**\n","\n","Parallel to the main workflow, the Logger class maintains two separate log files throughout execution. Every time an agent calls the LLM wrapper, the wrapper automatically calls the logger's log_prompt_response method after successful validation.\n","\n","This method creates a log entry containing the step identifier, timestamp, agent name, redacted prompt text, redacted response text, a hash of the prompt, a hash of the response, and critically, the hash of the previous log entry. This last field creates the hash chain that makes the log immutable.\n","\n","Each log entry is appended to the prompts_log.jsonl file as a single line of JSON. The jsonl format (JSON Lines) allows the file to grow without being loaded entirely into memory. The hash chain means that if anyone tried to modify an earlier entry, all subsequent entries' prev_hash values would no longer match, immediately revealing the tampering.\n","\n","Separately, whenever any component detects a risk (the wrapper detecting problematic patterns, the orchestrator finding unresolved hinge facts, or agents explicitly identifying risks in their outputs), an entry gets appended to the risk_log.json file. This file accumulates all risks from all cases in a single register, making it easy to review all problems in one place.\n","\n","**Stage 10: Package Assembly - Creating the Deliverable**\n","\n","After all cases complete execution, Cell 10 assembles the complete supervision package. The README generator creates comprehensive documentation by combining the run manifest, case results, governance explanations, supervision checklists, and technical details into a single 5000-word markdown document.\n","\n","The package_summary.json generator creates a machine-readable summary by extracting key information from the run manifest and case results into a structured JSON object. This allows automated tools to process packages without parsing markdown.\n","\n","The ZIP bundler recursively walks through the entire run directory and compresses all files while preserving folder structure. The resulting archive contains everything: manifest, README, summary, immutable logs, risk register, and individual case folders with their artifacts, registers, and checkpoint histories.\n","\n","**The Complete Pipeline in Summary**\n","\n","The pipeline transforms unstructured text into governed advisory artifacts through ten distinct stages. Raw scenarios become structured intake JSON through AI processing with quality controls. Structured intake feeds sequential specialized agents, each producing standardized JSON outputs. Human checkpoints gate progression between stages. Quality control agents examine accumulated artifacts for problems. All interactions get logged immutably with hash chaining. All risks get accumulated in a central register. All assumptions and open items get tracked in registers. All artifacts get saved in organized case folders. Everything gets packaged into a supervision-ready archive.\n","\n","This architecture demonstrates how generative AI can augment professional advisory workflows while maintaining the governance controls necessary for regulated industries. The strict JSON structuring at every stage ensures consistency, auditability, and scope enforcement. The multi-agent pattern allows specialization while maintaining coordination. The checkpoint mechanism preserves human primacy in decision-making. The immutable logging provides regulatory-grade audit trails. Together, these elements create a production-viable system that increases advisor productivity without compromising compliance or professional responsibility."],"metadata":{"id":"aV65a4QjNzQV"}},{"cell_type":"code","source":[],"metadata":{"id":"3BdM6IPANlZ-"},"execution_count":null,"outputs":[]}]}